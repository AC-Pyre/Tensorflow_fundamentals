{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zonEhh4cXtsr8QZtvTiq5h6mklfIxjv8",
      "authorship_tag": "ABX9TyOtSJa18d4QnW4F1epRCZQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AC-Pyre/Tensorflow_fundamentals/blob/main/01_neural_network_regression_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWv0ddcuhl7g"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: prediction a numerical variable based on some other combination of variables, even shorter... predicting a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszMKdkQw8xV"
      },
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "_NzgbXcjxDAh",
        "outputId": "13076ab9-c1e3-4cfe-f843-572e901840cb"
      },
      "source": [
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "Y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, Y);\n",
        "\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqud72Owx6Ne"
      },
      "source": [
        "## Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY8PKbsly78G",
        "outputId": "6fa8e906-e5ef-4506-dab6-e425fc36b88b"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bdIKe-s0VKS",
        "outputId": "2279d091-ffd2-4f89-dff0-3dd9e41a0526"
      },
      "source": [
        "input_shape = X.shape\n",
        "output_shape = Y.shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-_t5kEw0sjY",
        "outputId": "ae2e4bf3-b247-470e-ff11-9d56edda5867"
      },
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "Y = tf.constant(Y)\n",
        "X, Y"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbGOjCi11qhW",
        "outputId": "a9cf1cba-7d6e-4265-d7c5-754c9ebb9ec2"
      },
      "source": [
        "input_shape = X[0].shape \n",
        "output_shape = Y[0].shape \n",
        "input_shape, output_shape\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJgWLeIy2C1W"
      },
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as  the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X & Y (features and labels)\n",
        "4. **Evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCpIbE7j3Nlc",
        "outputId": "d4a0f826-1a8b-463d-d383-dd6fd7be6980"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # sgd is short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, Y, epochs=5)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbfa21004d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GtjkXad5i2P",
        "outputId": "7421a451-90d9-4e89-a985-31f62cb8658c"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hDMXOWA6dDX"
      },
      "source": [
        "## Improve our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of layer.\n",
        "2. **Compiling a model** - Here we might change the optimization fucntion or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer or on more data (five the model more examples to learn from).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aODSZDeOqqhE",
        "outputId": "b2350a03-794f-46c6-ac8e-f00fd411dd6d"
      },
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "#1 create the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2 Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3 Fit the model\n",
        "model.fit(X, Y, epochs=100)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbfa21177d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfThTdMBwXJe",
        "outputId": "c23cb474-a391-4c79-a9f6-cb26f59bacfc"
      },
      "source": [
        "# Remind ourselves of the data\n",
        "X, Y"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt6Ju6KGw6wa",
        "outputId": "318466be-a268-4a06-fc6b-1d6d1d1dbad7"
      },
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.])"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcyKChgRxEPi",
        "outputId": "cff7d958-f1d3-4eb7-a3d6-f6a9da0084d1"
      },
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "  # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=.1),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model_1.fit(X, Y, epochs=100)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 10.5736 - mae: 10.5736\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1236 - mae: 10.1236\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.6736 - mae: 9.6736\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.2236 - mae: 9.2236\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7736 - mae: 8.7736\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.3236 - mae: 8.3236\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8736 - mae: 7.8736\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.4236 - mae: 7.4236\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9736 - mae: 6.9736\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8250 - mae: 6.8250\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7706 - mae: 6.7706\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9023 - mae: 6.9023\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9798 - mae: 6.9798\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0115 - mae: 7.0115\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0041 - mae: 7.0041\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9629 - mae: 6.9629\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7967 - mae: 6.7967\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6786 - mae: 6.6786\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5410 - mae: 6.5410\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3862 - mae: 6.3862\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2161 - mae: 6.2161\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0324 - mae: 6.0324\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9317 - mae: 5.9317\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.8711 - mae: 5.8711\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8089 - mae: 5.8089\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7619 - mae: 5.7619\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7609 - mae: 5.7609\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7017 - mae: 5.7017\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5917 - mae: 5.5917\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4656 - mae: 5.4656\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3926 - mae: 5.3926\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3197 - mae: 5.3197\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2467 - mae: 5.2467\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1738 - mae: 5.1738\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1009 - mae: 5.1009\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0279 - mae: 5.0279\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9770 - mae: 4.9770\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9214 - mae: 4.9214\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8387 - mae: 4.8387\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7472 - mae: 4.7472\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6789 - mae: 4.6789\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6100 - mae: 4.6100\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5405 - mae: 4.5405\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4706 - mae: 4.4706\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4002 - mae: 4.4002\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3295 - mae: 4.3295\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2584 - mae: 4.2584\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1869 - mae: 4.1869\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1152 - mae: 4.1152\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0432 - mae: 4.0432\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9710 - mae: 3.9710\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8986 - mae: 3.8986\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8259 - mae: 3.8259\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7531 - mae: 3.7531\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6802 - mae: 3.6802\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6071 - mae: 3.6071\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5339 - mae: 3.5339\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4605 - mae: 3.4605\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3871 - mae: 3.3871\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3135 - mae: 3.3135\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2399 - mae: 3.2399\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1662 - mae: 3.1662\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0924 - mae: 3.0924\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0220 - mae: 3.0220\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9468 - mae: 2.9468\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8747 - mae: 2.8747\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8024 - mae: 2.8024\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7299 - mae: 2.7299\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6571 - mae: 2.6571\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5841 - mae: 2.5841\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5110 - mae: 2.5110\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4377 - mae: 2.4377\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3642 - mae: 2.3642\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.2906 - mae: 2.2906\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2169 - mae: 2.2169\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1431 - mae: 2.1431\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0692 - mae: 2.0692\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0054 - mae: 2.0054\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9234 - mae: 1.9234\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8512 - mae: 1.8512\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7788 - mae: 1.7788\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7061 - mae: 1.7061\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6331 - mae: 1.6331\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5600 - mae: 1.5600\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4867 - mae: 1.4867\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4132 - mae: 1.4132\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3395 - mae: 1.3395\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2657 - mae: 1.2657\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1918 - mae: 1.1918\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1178 - mae: 1.1178\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0437 - mae: 1.0437\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9695 - mae: 0.9695\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8952 - mae: 0.8952\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8208 - mae: 0.8208\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7464 - mae: 0.7464\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6828 - mae: 0.6828\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5997 - mae: 0.5997\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5291 - mae: 0.5291\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4521 - mae: 0.4521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbfa1f68ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6dMc2Vd2fo4",
        "outputId": "465df42a-9a5f-4633-d4eb-d220ae8c859f"
      },
      "source": [
        "model_1.predict([17.])"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.497078]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv41ZKlr2mpj",
        "outputId": "42abc71e-0cb1-4098-cec2-4f564ee3c209"
      },
      "source": [
        "# More improving, just add hidden layer\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model.fit(X, Y, epochs=100)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 14.0407 - mae: 14.0407\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.4800 - mae: 13.4800\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.9217 - mae: 12.9217\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3612 - mae: 12.3612\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.7937 - mae: 11.7937\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.2106 - mae: 11.2106\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6209 - mae: 10.6209\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0058 - mae: 10.0058\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3625 - mae: 9.3625\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6887 - mae: 8.6887\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9730 - mae: 7.9730\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2130 - mae: 7.2130\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3984 - mae: 6.3984\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5215 - mae: 5.5215\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5762 - mae: 4.5762\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0920 - mae: 4.0920\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0292 - mae: 4.0292\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9887 - mae: 3.9887\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9591 - mae: 3.9591\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8951 - mae: 3.8951\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9391 - mae: 3.9391\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8718 - mae: 3.8718\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9498 - mae: 3.9498\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8853 - mae: 3.8853\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9245 - mae: 3.9245\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8929 - mae: 3.8929\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8991 - mae: 3.8991\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9005 - mae: 3.9005\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8734 - mae: 3.8734\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9084 - mae: 3.9084\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8507 - mae: 3.8507\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9226 - mae: 3.9226\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8550 - mae: 3.8550\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9021 - mae: 3.9021\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8628 - mae: 3.8628\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8763 - mae: 3.8763\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8707 - mae: 3.8707\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8504 - mae: 3.8504\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8787 - mae: 3.8787\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8298 - mae: 3.8298\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8932 - mae: 3.8932\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8259 - mae: 3.8259\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8783 - mae: 3.8783\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8339 - mae: 3.8339\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8523 - mae: 3.8523\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8420 - mae: 3.8420\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8262 - mae: 3.8262\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8517 - mae: 3.8517\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8055 - mae: 3.8055\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8648 - mae: 3.8648\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7979 - mae: 3.7979\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8533 - mae: 3.8533\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8061 - mae: 3.8061\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8270 - mae: 3.8270\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8144 - mae: 3.8144\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8006 - mae: 3.8006\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8264 - mae: 3.8264\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7796 - mae: 3.7796\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8376 - mae: 3.8376\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7710 - mae: 3.7710\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8270 - mae: 3.8270\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7794 - mae: 3.7794\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8004 - mae: 3.8004\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7879 - mae: 3.7879\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7737 - mae: 3.7737\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8027 - mae: 3.8027\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7524 - mae: 3.7524\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8114 - mae: 3.8114\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7451 - mae: 3.7451\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7994 - mae: 3.7994\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7537 - mae: 3.7537\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7726 - mae: 3.7726\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7624 - mae: 3.7624\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7474 - mae: 3.7474\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7774 - mae: 3.7774\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7238 - mae: 3.7238\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7863 - mae: 3.7863\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7203 - mae: 3.7203\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7705 - mae: 3.7705\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7290 - mae: 3.7290\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7433 - mae: 3.7433\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7379 - mae: 3.7379\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7196 - mae: 3.7196\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7531 - mae: 3.7531\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6939 - mae: 3.6939\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7622 - mae: 3.7622\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6964 - mae: 3.6964\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7403 - mae: 3.7403\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7054 - mae: 3.7054\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7128 - mae: 3.7128\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7145 - mae: 3.7145\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6903 - mae: 3.6903\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7299 - mae: 3.7299\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6645 - mae: 3.6645\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7364 - mae: 3.7364\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6735 - mae: 3.6735\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7087 - mae: 3.7087\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6827 - mae: 3.6827\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6808 - mae: 3.6808\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6927 - mae: 3.6927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbfa1e05e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00PYaRtg5ijb",
        "outputId": "1ae4a12a-cc10-4c6e-dbfe-8fa8fd4cd4a7"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.727652]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_VuGkFF5orQ"
      },
      "source": [
        "### Common ways to improve a deep model:\n",
        "\n",
        "* adding layers\n",
        "* increase the number of hidden units\n",
        "* change the activation functions\n",
        "* change the omptimization function\n",
        "* change the learning rate (lr) (on Adam) (potentially the most important yperparamater of many learning models)\n",
        "* fitting more data\n",
        "* fitting for longer (add epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xshk_Vok7GbT"
      },
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "build a model -> fit it -> evaluate it -> tweek it -> fit it -> evaluate it -> tweek it... ect...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVwlUbEh7z5s"
      },
      "source": [
        "### when it comes to evaluation... there are three words you should memorize:\n",
        "\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "its a good idea to visualize:\n",
        "* the data - what data are we working with? what does it look like?\n",
        "* the model itself - what does our model look like?\n",
        "* the training of a model - how does a model perform while it learns?\n",
        "* the predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lPWFqTn9WAu",
        "outputId": "d2209fbb-b84e-4e47-bef9-3b5c905db6c4"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4RVWMVb9fYd",
        "outputId": "e5edeeab-b341-4a7a-9c37-0e8028e5de0f"
      },
      "source": [
        "# Make labels for the dataset\n",
        "Y = X + 10\n",
        "Y\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7z1Xs9ED9oct",
        "outputId": "061fb835-59e4-4478-bd35-dad98600d0f5"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X, Y)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fbf8e071e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7J9Osjb9x8v"
      },
      "source": [
        "# The three sets... (possibly the most important concept in machine learning)\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available\n",
        "  * (course materials)\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "  * (Practice exam)\n",
        "* **Test set** - the model gets evaluated on this data to test what has been learned, this set is typically 10-15% of the total data available.\n",
        "  * (final exam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7evvzqKI-lGg",
        "outputId": "f339db47-e75b-40c6-eb1a-54bac0c5a790"
      },
      "source": [
        "# check the length of how many samples we have\n",
        "len(X)\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeTSaoB7_Nlp",
        "outputId": "23bdefad-d491-4704-c695-5dd9934742df"
      },
      "source": [
        "# Split the data into train at test sets\n",
        "x_train = X[:40] # first 40 are training sampels (80% of the data)\n",
        "y_train = Y[:40]\n",
        "\n",
        "x_test = X [40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = Y[40:]\n",
        "\n",
        "len(x_train), len(x_test), len(y_train), len(y_test)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqOKhVXOFzhl"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got our data in training and test sets... let's visualize it again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "-RqB1YasGXfv",
        "outputId": "c9c801b7-3ae2-4d6e-fff8-75157ac4b7ba"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(x_train, y_train, c=\"b\", label=\"Training data\")\n",
        "#plot test data in green\n",
        "plt.scatter(x_test, y_test, c=\"g\", label=\"Testing data\")\n",
        "plt.legend();"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jsduZ2iG684"
      },
      "source": [
        "# Let's have a look at how to build a neural network\n",
        "\n",
        "# 1. Creat the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "# model.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "gmbeVnDQH7lz",
        "outputId": "77fe80d1-fdac-4af3-f4f1-05a3a9d4e0e9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2475\u001b[0m     \"\"\"\n\u001b[1;32m   2476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2478\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8RkkDvzID-z"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the imput_shape argument\n",
        "# create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1, input_shape=[1], name=\"input_layer\"),\n",
        "  tf.keras.layers.Dense(1, name=\"output_layer\")\n",
        "], name=\"model_1\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9LVLGbsI3Xz"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPmb1S1gI9kY"
      },
      "source": [
        "* Total params - total number of parameters in the model.\n",
        "* Trainable params - these are the parameters (patterns) the model can update as it trains\n",
        "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learned patterns or parameters from other models during **transfer learning**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VP88D5JJ-Qg"
      },
      "source": [
        "# Let's fit our model to the training data\n",
        "model.fit(x_train, y_train, epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI_hINwNNCH6"
      },
      "source": [
        "# Get a summary of our model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nMbr4FnNUjv"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16mlZGO2nA-X"
      },
      "source": [
        "### Visualizing our model's predictions\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of `y_test` or `y_true` vs `y_pred` (ground truth versus your model's predictions).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4l_7WCEpDCP"
      },
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg3vYLoept3J"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUsF-ZMbqE_1"
      },
      "source": [
        "### **Note:** If you feel like you're going to reuse some kind of functionality in the future, its' a good idea to turn it into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfJrCjLap1aa"
      },
      "source": [
        "# Let's create a plotting function\n",
        "def plot_predictions(train_data=x_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=x_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth 1\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot model's predictions in red\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  #Show the legend\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDveZPSbq30_"
      },
      "source": [
        "plot_predictions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WrgRg5GsxDN"
      },
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performence.\n",
        "\n",
        "Since we're working on a regression, two of the main metrics\"\n",
        "* MAE - mean absolute error, \"on average, how lwrong is each of my model's predictions\"\n",
        "  * Great as a starter\n",
        "* MSE - mean square error, \"square the average errors\"\n",
        "  * When larger errors are more significant than smaller errors\n",
        "* Huber - Combination of MSE and MAE. \n",
        "  * Less sensitive to outliers than MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDtQk6-VuOhL"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqiAb4sCxsuW"
      },
      "source": [
        "# Calculate the mean absolute error\n",
        "tf.metrics.mean_absolute_error(y_test, tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_2WQ9I2yPAO"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrD9V5zcy6Gv"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daus8LVVy668"
      },
      "source": [
        "# Caluculate the mean square error\n",
        "tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                              y_pred=tf.squeeze(y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG9a3tuC1NeD"
      },
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                        y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn9Y52Vh21xq"
      },
      "source": [
        "### Running experiments to improve our model\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> tweak it ect...\n",
        "```\n",
        "\n",
        "1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
        "2. Make your model larger (using a more complex model) - this might come int the form of more layers or more hidden units in each layer\n",
        "3. Train for longer - give your model more of a chance to find patterns in the data.\n",
        "\n",
        "Let's do 3 modelling experiments:\n",
        "\n",
        "1. `model_1` - same as the original model, 1 layer, trainded for 100 epochs\n",
        "2. `model_2` - 2 layers, trained for 100 epochs\n",
        "3. `model_3` - 2 layers, trained for 500 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEMWRs0y3aEZ"
      },
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqv1uLlH30Yu"
      },
      "source": [
        "# Make and plot precitions for model_1\n",
        "y_preds_1 = model_1.predict(x_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Jvmdt25eRR"
      },
      "source": [
        "# Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "mae_1.numpy(), mse_1.numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7_eytzF58SM"
      },
      "source": [
        "**Build `model_2`**\n",
        "\n",
        "* 2 dense layers, trainded for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFVXxXFg64mg"
      },
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKIcnTjQ7BsK"
      },
      "source": [
        "y_preds_2 = model_2.predict(x_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZiciG6d7LGx"
      },
      "source": [
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test, y_preds_2)\n",
        "mae_2.numpy(), mse_2.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69qU26Il7Tdq"
      },
      "source": [
        "**Build `model_3`**\n",
        "* 2 layers trained for 500 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWpBUX-c8TrQ"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(x_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InSIDtC8021"
      },
      "source": [
        "y_preds_3 = model_3.predict(x_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1gy1KZZ9SGX"
      },
      "source": [
        "mae_3 = mae(y_test, y_preds_3)\n",
        "mse_3 = mse(y_test, y_preds_3)\n",
        "mae_3, mse_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkBu5POc9sbN"
      },
      "source": [
        "## Comparing the results of our experiments\n",
        "\n",
        "We've run a few experiments, lets compare the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S8X7Zhh93oj"
      },
      "source": [
        "# Let's compare our model's results using a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QUZiQ4r_eN9"
      },
      "source": [
        "**Note:** One of your main goals should be to minimize the time between experiments. the more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figure out what does work. Remember the machine learning practitioner's motto: \"experiment, experiment, experiment\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPrOkuzaAwmi"
      },
      "source": [
        "## Tracking your experiments\n",
        "\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you're running lots of experiments\n",
        "\n",
        "Luckily, there are tools to help us!\n",
        "\n",
        "\n",
        "**Resource:** As you build more models, you'll want to look into using:\n",
        "* TensorBoard - a component of the tensorflow library to help track modelling experiments (we'll see this one later).\n",
        "* Weights & Biases - a tool for tracking all kinds of machine learning experiments (plugs straght into TensorBord)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic0qgqs7Bn-G"
      },
      "source": [
        "## Saving our models\n",
        "\n",
        "* Saving our models allows us to use them outside of Google collab\n",
        "\n",
        "There are two main formats we can saver our models's too:\n",
        "1. The Saved Model format\n",
        "2. The HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqDYJ8sxBuzC"
      },
      "source": [
        "model_2.save(\"best_model_savedModel_format\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlj317GPCiGy"
      },
      "source": [
        "# Save model using the HD5 format ( if using outside pure tensorflow code )\n",
        "model_2.save(\"best_model_HDF5_format.H5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45C34-LOtF_0"
      },
      "source": [
        "## Loading in a saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKTG2BM0t_qG"
      },
      "source": [
        "# Load in the savedModel format model\n",
        "loaded_savedModel_format = tf.keras.models.load_model(\"/content/best_model_savedModel_format\")\n",
        "loaded_savedModel_format.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzUEs6PiuQN7"
      },
      "source": [
        "# Compare model_2 predictions with SavedModel format model predictions\n",
        "model_2_preds = model_2.predict(x_test)\n",
        "loaded_savedModel_format_preds = loaded_savedModel_format.predict(x_test)\n",
        "model_2_preds == loaded_savedModel_format_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohvjmCLXu5C3"
      },
      "source": [
        "# Load in a model using the H5 format\n",
        "loaded_H5_model = tf.keras.models.load_model(\"/content/best_model_HDF5_format.H5\")\n",
        "loaded_H5_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgha9AudvwdD"
      },
      "source": [
        "# Check to see if loaded .h5 predictions match model_2\n",
        "model_2_preds = model_2.predict(x_test)\n",
        "loaded_H5_model_preds = loaded_H5_model.predict(x_test)\n",
        "model_2_preds == loaded_H5_model_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZQP5Ym5wSl1"
      },
      "source": [
        "## Download a model (or any other file) from Google Colab\n",
        "\n",
        "If you want to download your files from Google Colab:\n",
        "\n",
        "1. You can go to the \"files\" tab and right click on the file you're after and click \"download\".\n",
        "\n",
        "2. Use code(see cell below).\n",
        "3. Save it to google drive by connecting to google drive and downloading from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lqXKKaGx5dh"
      },
      "source": [
        "# Download a file from Google Colab\n",
        "# actually probably need to make it into a zip to be able to download it\n",
        "from google.colab import files\n",
        "files.download(\"/content/best_model_savedModel_format/saved_model.pb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ymPVWVJyCi8"
      },
      "source": [
        "# Save a file from Google colab to google drive (requires mounting google drive) \n",
        "# this one also requires making a zip\n",
        "\n",
        "!cp /content/best_model_HDF5_format.H5 /content/drive/MyDrive/colab_assets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3ZPBJv819eu"
      },
      "source": [
        "## A larger example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Yob7AE3dwA"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBEB1RcT4bkU"
      },
      "source": [
        "# Import \n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-K2bk1T4nWO"
      },
      "source": [
        "# Let's try and one-hot encode our DataFrame so it's all numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hc-tfND7oul"
      },
      "source": [
        "# Create x & y values (features and labels)\n",
        "# Creat training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdKS1a_K8q3P"
      },
      "source": [
        "# Create x & y values (features and labels)\n",
        "x = insurance_one_hot.drop(\"charges\", axis=1) # dropping the charges column to isolate indipendent variables\n",
        "y = insurance_one_hot[\"charges\"] # the charges column wil be the outcome variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVNHrdth_SJE"
      },
      "source": [
        "# view x and y\n",
        "x.head(), y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7tzxnpL_YAz"
      },
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "len(x), len(x_train), len(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRD-OmBKAGKR"
      },
      "source": [
        "#Build a neural network\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. fit the model\n",
        "insurance_model.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KplK2ke0BSBa"
      },
      "source": [
        " model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KWShax3BT_l"
      },
      "source": [
        "# Check the results of the insurance model on the test data\n",
        "insurance_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muV-WZRmC_ia"
      },
      "source": [
        "Right now it looks like our model isn't performing too well.. let's try and improve it\n",
        "\n",
        "To try and improve our model:\n",
        "1. Add an extra layer with more hidden units and use the adam optimizer\n",
        "2. train for longer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrdAivvyFJag"
      },
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(x_train, y_train, epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S958URIgF5YA"
      },
      "source": [
        "# Evaluate the larger model\n",
        "insurance_model_2.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qNBCeoiHMZx"
      },
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Creat the model (same as above)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_3.fit(x_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0C1rTtIZxk"
      },
      "source": [
        "# Evaluate our third model\n",
        "insurance_model_3.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjXcQT34I6y_"
      },
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GodtwXoeJ1AA"
      },
      "source": [
        "> **Question** How long should you train for?\n",
        "\n",
        "It depends on the problem you're working on, however many have asked this question before\n",
        "\n",
        "TesnsorFlow has a solution, it's called the EarlyStopping callback\n",
        "  * tensorflow component you can add to your model to have it stop at a certain improving metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgY2s-39GFQb"
      },
      "source": [
        "#Build a neural network\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(lr=.1),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. fit the model\n",
        "history_3 = insurance_model_4.fit(x_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnUYai9BKdtP"
      },
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "pd.DataFrame(history_3.history).plot()\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69GsPdnwKjl8"
      },
      "source": [
        "#Build a neural network\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model_5 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_5.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(lr=.001),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. fit the model\n",
        "history_5 = insurance_model_4.fit(x_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWFYlKKnLKep"
      },
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "pd.DataFrame(history_5.history).plot()\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9deiTR-wLZDL"
      },
      "source": [
        "## Preprocessing data (normalization and standardization)\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1-D0Y62P_7L"
      },
      "source": [
        "**Scaling type**\n",
        "\n",
        "* Scale (also referred to as normalization) - converts all values to between 0 and 1 whilst preserving the original distribution\n",
        "  * `MinMaxScaler` -Scikit-Learn function\n",
        "  * Use as default scaler with neural networks\n",
        "Standardization\n",
        "* Standardization - Removes the mean and divides each value by the standard deviation\n",
        "  * `StandardScaler` -Scikit-Learn function \n",
        "  * Transform a feature to have close to normal distribution (caution: this reduces the effect of outliers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4Qq2eSm4fVIO",
        "outputId": "87d5e8d5-2f18-4ad2-8582-a097ecef6b1e"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataframe\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nAIxgnQf9g8"
      },
      "source": [
        "To prepare our data we can borrow a few classes from Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o34wBbDzgIHj"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in thse columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "       X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the column transformer to our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normaliztion (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqkfaPSvj5uD",
        "outputId": "96c8ec82-cefa-49f8-e6c3-f0a621cdc98b"
      },
      "source": [
        "# What does our data look like now?\n",
        "X_train.loc[0]\n"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c29KXsIQkeWB",
        "outputId": "f90afd7e-4705-4867-ae8a-33dead47f458"
      },
      "source": [
        "X_train_normal[0]"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe4lD9kHk03E",
        "outputId": "801f138d-27c8-4a33-b514-c27c14e76f16"
      },
      "source": [
        "X_train.shape, X_train_normal.shape # because we normalized and hot encoded there are some extra columns"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz3PRMDhlEjp"
      },
      "source": [
        "Beautiful! Our data has been normalized and one hot encoded. Now lets build a neural network model with it."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV3bRolplPqd",
        "outputId": "61ee16db-2ae7-46e3-ae93-f29f563afaa6"
      },
      "source": [
        "# Build a neural network model to fit on our normalized data\n",
        "# set seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "insurance_model_6 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                              \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_6.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history_6 = insurance_model_4.fit(X_train_normal, y_train, epochs=100)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "19/34 [===============>..............] - ETA: 0s - loss: 1559.5446 - mae: 1559.5446"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 0s 3ms/step - loss: 1603.7906 - mae: 1603.7906\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1615.7332 - mae: 1615.7332\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1708.2437 - mae: 1708.2437\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1535.6909 - mae: 1535.6909\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1584.3438 - mae: 1584.3438\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1555.6421 - mae: 1555.6421\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1601.3098 - mae: 1601.3098\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1603.5149 - mae: 1603.5149\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1553.2830 - mae: 1553.2830\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1684.5206 - mae: 1684.5206\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1617.8372 - mae: 1617.8372\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1611.6373 - mae: 1611.6373\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1604.8768 - mae: 1604.8768\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1638.4878 - mae: 1638.4878\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1568.7639 - mae: 1568.7639\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1726.0597 - mae: 1726.0597\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1559.7595 - mae: 1559.7595\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1620.1583 - mae: 1620.1583\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1721.8229 - mae: 1721.8229\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1625.7493 - mae: 1625.7493\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1619.5863 - mae: 1619.5863\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1636.5385 - mae: 1636.5385\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1549.9338 - mae: 1549.9338\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1545.6559 - mae: 1545.6559\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1636.9515 - mae: 1636.9515\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1764.3837 - mae: 1764.3837\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1614.6697 - mae: 1614.6697\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1528.4955 - mae: 1528.4955\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1650.5732 - mae: 1650.5732\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1678.8302 - mae: 1678.8302\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1581.0306 - mae: 1581.0306\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1580.0427 - mae: 1580.0427\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1579.2771 - mae: 1579.2771\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1534.7616 - mae: 1534.7616\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1600.2391 - mae: 1600.2391\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1562.4481 - mae: 1562.4481\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1712.8354 - mae: 1712.8354\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1784.9762 - mae: 1784.9762\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1682.6301 - mae: 1682.6301\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1638.7212 - mae: 1638.7212\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1790.8519 - mae: 1790.8519\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1534.2261 - mae: 1534.2261\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1554.2930 - mae: 1554.2930\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1636.9242 - mae: 1636.9242\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1808.5612 - mae: 1808.5612\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1619.0751 - mae: 1619.0751\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1590.6652 - mae: 1590.6652\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1696.9819 - mae: 1696.9819\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1772.2661 - mae: 1772.2661\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1628.6628 - mae: 1628.6628\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1635.5488 - mae: 1635.5488\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1557.0662 - mae: 1557.0662\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1535.1980 - mae: 1535.1980\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1627.5684 - mae: 1627.5684\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1600.4877 - mae: 1600.4877\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1799.1006 - mae: 1799.1006\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1671.8613 - mae: 1671.8613\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1601.5580 - mae: 1601.5580\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1689.8829 - mae: 1689.8829\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1559.0365 - mae: 1559.0365\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1593.2327 - mae: 1593.2327\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1523.3154 - mae: 1523.3154\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1534.7148 - mae: 1534.7148\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1531.7295 - mae: 1531.7295\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1563.8735 - mae: 1563.8735\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1596.2427 - mae: 1596.2427\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1627.3085 - mae: 1627.3085\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1566.5900 - mae: 1566.5900\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1549.6835 - mae: 1549.6835\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1582.5396 - mae: 1582.5396\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1614.5542 - mae: 1614.5542\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1643.2419 - mae: 1643.2419\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1764.4883 - mae: 1764.4883\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1647.8730 - mae: 1647.8730\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1646.4786 - mae: 1646.4786\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1556.1227 - mae: 1556.1227\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1669.7885 - mae: 1669.7885\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1647.2548 - mae: 1647.2548\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1592.5802 - mae: 1592.5802\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1564.3478 - mae: 1564.3478\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1583.6504 - mae: 1583.6504\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1586.3673 - mae: 1586.3673\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1642.8134 - mae: 1642.8134\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1606.5100 - mae: 1606.5100\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1584.0283 - mae: 1584.0283\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1676.2670 - mae: 1676.2670\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1696.9677 - mae: 1696.9677\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1564.7966 - mae: 1564.7966\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1571.9166 - mae: 1571.9166\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1614.6345 - mae: 1614.6345\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1524.0371 - mae: 1524.0371\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1568.5004 - mae: 1568.5004\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1529.7675 - mae: 1529.7675\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1821.0369 - mae: 1821.0369\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1527.7500 - mae: 1527.7500\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1609.2169 - mae: 1609.2169\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1613.4714 - mae: 1613.4714\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1623.3538 - mae: 1623.3538\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1618.3289 - mae: 1618.3289\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1649.7977 - mae: 1649.7977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwLUGzIsmV3A"
      },
      "source": [
        "# Evaluate our insurance model trained on normalized data\n",
        "insurance_model_4.evaluate(X_test_normal, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "g15bUenynXNw",
        "outputId": "5a1d4c48-a52e-4dea-84fd-9c22f8641dc5"
      },
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "pd.DataFrame(history_6.history).plot()\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d5hk2V2f/557b93KVR0nx81hVhu0Qau1VkLArgTYMsGCNT9JK4LwzwRbMgJEMMIGgQUYYwEC2VqQDMoSZoXyConVSptz0uyEndAzPdO5crjh+I9zb4Xuquqq3u7p3p7zPk8/033rVtWpqar7Od8spJRoNBqNRtMLY70XoNFoNJqNjxYLjUaj0SyLFguNRqPRLIsWC41Go9EsixYLjUaj0SyLtd4LWAvGxsbkvn371nsZGo1G87Li0UcfnZFSjne6bVOKxb59+3jkkUfWexkajUbzskIIcbzbbdoNpdFoNJpl0WKh0Wg0mmXRYqHRaDSaZdmUMQuNRqNZKY7jMDExQbVaXe+lrBmxWIxdu3YRiUT6vo8WC41Go2lhYmKCdDrNvn37EEKs93JWHSkls7OzTExMsH///r7vp91QGo1G00K1WmV0dHRTCgWAEILR0dGBLSctFhqNRrOIzSoUISt5fVosNJrziBMvPMEz99293svQvAzRYqHRnEec/eIfMHrPu9Z7GZplSKVS672EJWix0GjOI0ynSARnvZeheRmixUKjOY+wvCoW7novQ9MnUkre/e53c+DAAa666io++clPAjA5Ocmtt97KNddcw4EDB/jWt76F53nceeedjXP/5E/+ZFXXolNnNZrzCMurYElvvZfxsuF3Pv8sz53Or+pjXrEjw2//yyv7Ovdzn/scTzzxBE8++SQzMzPccMMN3HrrrXzsYx/j9ttv5zd+4zfwPI9yucwTTzzBqVOneOaZZwBYWFhY1XVry0KjOY+w/QomWixeLtx3333ccccdmKbJ1q1bee1rX8vDDz/MDTfcwF//9V/z3ve+l6effpp0Os0FF1zA0aNH+cVf/EW+/OUvk8lkVnUt2rLQaM4jbFnF0mLRN/1aAOeaW2+9lXvvvZcvfOEL3HnnnbzrXe/irW99K08++SRf+cpX+Mu//Es+9alPcdddd63ac2rLQqM5j7D9GhHhIX1/vZei6YPXvOY1fPKTn8TzPKanp7n33nu58cYbOX78OFu3buVnf/Zn+Zmf+Rkee+wxZmZm8H2fH/3RH+V3f/d3eeyxx1Z1LWtmWQghdgMfBbYCEviQlPJPhRAjwCeBfcAx4M1SynmhqkT+FPgBoAzcKaV8LHistwG/GTz070opP7JW69ZoNjMxVNWu6zpE7Og6r0azHD/8wz/M/fffz9VXX40Qgve///1s27aNj3zkI/zhH/4hkUiEVCrFRz/6UU6dOsXb3/52/GAj8Pu///uruhYhpVzVB2w8sBDbge1SyseEEGngUeBfA3cCc1LKPxBC/BowLKX8VSHEDwC/iBKLm4A/lVLeFIjLI8D1KNF5FHillHK+23Nff/31Ug8/0miWUvvtMaLCoforp4glNl4u/0bg+eef5/LLL1/vZaw5nV6nEOJRKeX1nc5fMzeUlHIytAyklAXgeWAn8CYgtAw+ghIQguMflYoHgKFAcG4HvialnAsE4mvAG9Zq3RrNZsVzXaJC1Vg4Tn2dV6N5uXFOYhZCiH3AtcCDwFYp5WRw0xmUmwqUkJxsudtEcKzb8cXP8Q4hxCNCiEemp6dXdf0azWagUi40fve0WGgGZM3FQgiRAj4L/EcpZVvCslQ+sFXxg0kpPySlvF5Kef34eMd54xrNeU21RSxcV4uFZjDWVCyEEBGUUPydlPJzweGzgXspjGtMBcdPAbtb7r4rONbtuEajGYBaq1hoy0IzIGsmFkF204eB56WU/73lpruBtwW/vw34h5bjbxWKVwG5wF31FeA2IcSwEGIYuC04ptFoBqBeKTZ+913d8kMzGGtZlHcL8BbgaSHEE8GxXwf+APiUEOKngePAm4PbvojKhDqMSp19O4CUck4I8V+Bh4Pz/ouUcm4N163RbEpqLWLhubV1XInm5ciaiYWU8j6g24SN7+1wvgR+vstj3QWsXimiRnMe4raJhe48qxkMXcGt0ZwnuNVS43edDaUZFC0WGs15gltvEQttWWxojh07xmWXXcadd97JJZdcwk/+5E9yzz33cMstt3DxxRfz0EMP8dBDD3HzzTdz7bXX8upXv5qDBw8C4Hke7373u7nhhht4xStewV/91V+typp0I0GN5jzBb7EsfE+LRV986dfgzNOr+5jbroI3/sGypx0+fJhPf/rT3HXXXdxwww187GMf47777uPuu+/mfe97Hx/96Ef51re+hWVZ3HPPPfz6r/86n/3sZ/nwhz9MNpvl4Ycfplarccstt3Dbbbexf//+l7RsLRYazXmC32JZ+Nqy2PDs37+fq666CoArr7yS7/3e70UIwVVXXcWxY8fI5XK87W1v49ChQwghcBz1nn71q1/lqaee4jOf+QwAuVyOQ4cOabHQaDT9IdvEQscs+qIPC2CtiEabjR4Nw2j8bRgGruvyW7/1W3zP93wPf//3f8+xY8d43eteB6jpeh/4wAe4/fbbV3U9Omah0ZwvOJXGr9qyePmTy+XYuVN1Pvqbv/mbxvHbb7+dD37wgw1L44UXXqBUKnV6iIHQYqHRnCcIp9z43fd1Ud7LnV/5lV/hPe95D9deey1uS5Hlz/zMz3DFFVdw3XXXceDAAX7u536u7faVsmYtytcT3aJco1nKg//zLdw0dzcAj938Z1x3+1vWeUUbE92i/By3KNdoNBsL021aFtLTMQvNYGix0GjOE0yvSl2qnBapYxaaAdFiodGcJ5hehYJIArrOYjk2o3u+lZW8Pi0WGs15QsSrUA7EAh3g7kosFmN2dnbTCoaUktnZWWKx2ED303UWGs15QsSvUTFT4ILUlkVXdu3axcTEBJt54mYsFmPXrl0D3UeLhUZznhD1KyzYW7VYLEMkEnnJ1c6bEe2G0mjOE6KyihNJqz+0WGgGRIuFRnOeEKOGG8kAIH1vnVejebmhxUKjOU+IyRq+HVoWus5CMxhaLDSa8wDXqWMLFxnLqgM6G0ozIFosNJrzgHKpAICwEzjS1DELzcBosdBozgNq5VAskngYCG1ZaAZEi4VGcx5QKxcBMKNJXCzthtIMjBYLjeY8oFYJxSKBK0yEr91QmsHQYqHRnAc4FeWGMqMpbVloVoQWC43mPMCpKssiEk/hYeqYhWZgtFhoNOcBblWN1YzEUnjCxNBuKM2AaLHQaM4DvJoSCzuexMNCSF3BrRkMLRYazXmAH4hFNJHGE9oNpRkcLRYazXmAX1cjVWOJDJ6wEFKLhWYwtFhoNOcDDbFI4qNjFprB0WKh0ZwHSKeEKw1sO4YvLAwds9AMiBYLjeY8QDhlKkQRhoEnLAzthtIMiBYLjeY8wHArVIWauewbWiw0g7NmYiGEuEsIMSWEeKbl2NVCiPuFEE8LIT4vhMi03PYeIcRhIcRBIcTtLcffEBw7LIT4tbVar0azmTHcCjURBcAXFqYWC82ArKVl8TfAGxYd+9/Ar0kprwL+Hng3gBDiCuAngCuD+/yFEMIUQpjAnwNvBK4A7gjO1Wg0A2C6ZeqBZSGFqWMWmoFZM7GQUt4LzC06fAlwb/D714AfDX5/E/AJKWVNSvkicBi4Mfg5LKU8KqWsA58IztVoNANgeRXqRhwILQstFprBONcxi2dpXuz/DbA7+H0ncLLlvIngWLfjSxBCvEMI8YgQ4pHp6elVXbRG83In4tdwzMCyMCwMtBtKMxjnWix+Cvj3QohHgTSwaoOApZQfklJeL6W8fnx8fLUeVqPZFET8Cq4ZWBZGRMcsNANjncsnk1J+F7gNQAhxCfCDwU2naFoZALuCY/Q4rtFo+iTqV/ECsZDCwtJuKM2AnFPLQgixJfjXAH4T+MvgpruBnxBCRIUQ+4GLgYeAh4GLhRD7hRA2Kgh+97lcs0azGYjKKr4ViIVhYmo3lGZA1syyEEJ8HHgdMCaEmAB+G0gJIX4+OOVzwF8DSCmfFUJ8CngOcIGfl1JtfYQQvwB8BTCBu6SUz67VmjWazUqUGn4kAYA0Iphoy0IzGGsmFlLKO7rc9Kddzv894Pc6HP8i8MVVXJpGc94RlzVkYFlgWFhaLDQDoiu4NZpNTr1WJSI8sJuWhaUD3JoB0WKh0WxyKmU1UlXYSUDFLLRloRkULRYazSanVi4AYARigY5ZaFaAFguNZpNTK+cBMAI3FGYEU0h8TwuGpn+0WGg0m5xa4IYyYykAhBEBwHFq67YmzcsPLRYazSbHrar521YscEOZKgnSdVatgYLmPECLhUazyXGqyrKIRMOYRSgWerSqpn+0WGg0mxwnsCwi8cANZSo3lOdqy0LTP1osNJpNjl9TloWdSKsDDbHQloWmf7RYaDSbHK9WBiAWiIURiIWrA9yaAdBiodFscmRduaHswA3VsCx0zEIzAFosNJpNTigWiaSyLESQDeV5uuWHpn+0WGg0mx2nQl2aROwo0HRD+a52Q2n6R4uFRrPJEU6Zqog1/9YBbs0K0GKh0WxyDLdMlWjzb8sGwNNFeZoB0GKh0WxyTLdCrcWyMKzADeVpy0LTP1osNJpNTrQ+R82IN/4OA9y+qwPcmv7RYqHRbGJyc9NcUn2amfFXNY6ZgRvK97QbStM/Wiw0mk3MwX/+BLbwGLnxzY1jzWwo7YbS9I8WC41mExN94W4mGefia25tHDMjgWWhe0NpBkCLhUazScnNTXN5+VGOb7sNYTS/6qFlIXWAWzMAWiw0mk1KJxcUgBlmQ/k6wK3pHy0WGs0mpZMLCpoBbqljFpoB0GKh0WxCurmgAMyIsizQbijNAGix0Gg2Id1cUABWRFVz66I8zSBosdAMzPGDTzDxO5cyc+bEei9F04XIoS92dEEBGEFRHjpmoRkALRaagZk++AC75Bmmjj233kvRdCFVn2Yqvn+JCwqaloXOhtIMghYLzcC4xRkAnEphnVei6UbEr+KZsY63WTpmoVkBWiw0g1OeA8CtFNd5IZpu2LKGZ8Y73mYFRXno4UeaAdBioRkYUZ0HwKtpy2KjYss6vtXZsoiEbihfWxaa/tFioRkYq6osC7+qLYuNSkzWkFZny8IwTXwpdIBbMxBaLDQDE3UWAJB1LRYblSh1ZBfLAsDF1G4ozUCsmVgIIe4SQkwJIZ5pOXaNEOIBIcQTQohHhBA3BseFEOJ/CiEOCyGeEkJc13KftwkhDgU/b1ur9Wr6J+7m1S/10vouRNMRp14jIjyIdLYsQImF0G4ozQCspWXxN8AbFh17P/A7UsprgP8c/A3wRuDi4OcdwAcBhBAjwG8DNwE3Ar8thBhewzVr+iDl5QAQWiw2JNWKel9EL7EQlhYLzUCsmVhIKe8F5hYfBjLB71ngdPD7m4CPSsUDwJAQYjtwO/A1KeWclHIe+BpLBUhzjslIFdg2HC0WG5FakKUmIomu53iYOmahGQjrHD/ffwS+IoT4I5RQvTo4vhM42XLeRHCs2/ElCCHegbJK2LNnz+quWtOgUioQF2oOgulV1nk1mk7UK2UADHs5N5QWC03/9GVZCCH+gxAiE8QWPiyEeEwIcdsKnu//B94ppdwNvBP48AoeoyNSyg9JKa+XUl4/Pj6+Wg+rWURu7mzjd8str+NKNN2oB1lqhp3seo6HpcVCMxD9uqF+SkqZB24DhoG3AH+wgud7G/C54PdPo+IQAKeA3S3n7QqOdTuuWSdK81ON3y1Pi8VGxKmq98WM9opZmAipxULTP/2KhQj+/QHg/0gpn205NgingdcGv78eOBT8fjfw1sByeRWQk1JOAl8BbhNCDAeB7duCY5p1orwwDUBRxrG1G2pD4lRVLMmK9ohZCAtDB7g1A9BvzOJRIcRXgf3Ae4QQacDvdQchxMeB1wFjQogJVFbTzwJ/KoSwgCpBjAH4IkqIDgNl4O0AUso5IcR/BR4OzvsvUsrFQfNNz7Pf+SKX33Q7hmmu91KoF5RYTJtbiEotFhsRt6Ysi15i4WMipHeulqTZBPQrFj8NXAMclVKWg5TWt/e6g5Tyji43vbLDuRL4+S6PcxdwV5/r3HQcf/5RrvzqHTxZ/V9c/fqlswnONW5xFoBcdDs7Ki+s82o0nQjFIhJLdT3HEzpmoRmMft1QNwMHpZQLQoj/D/hNILd2y9KElBZUjKCWO7POK1H4JSUWteQOYlTXeTWaTvh1JRZ2rHvMwhcmho5ZaAagX7H4IFAWQlwN/CfgCPDRNVuVpkHYBtwvL6zzShSiMkeeBH40S0JWkX5Pb6RmHWiIRby3ZaHFQjMI/YqFG7iK3gT8mZTyz4H02i1LE+JWlVjI6sYw5KzaPAWRBjuJJXxqNR232Gj4dfWeRGPdU2d9YWFoN5RmAPoVi4IQ4j2olNkvCCEMILJ2y9KEhJ1dxQYRC7u+QMnMYkTVrrVSzK/zis4/nvn255mb6p5BLh0lFrFEd8tCuaF0gFvTP/2KxY8DNVS9xRlUvcMfrtmqNA28mkqDNOsbY3ZE3M1RsbKIUCxKWizOJfValUu/+jYO3v1H3U9yQsuiRzaUsDDRloWmf/oSi0Ag/g7ICiF+CKhKKXXM4hwQtgG3nI1xUU56eRx7CCvItKmVN8a6zhdmJo8TER5m6WzXc4RTpiLtjvO3Q3wjomMWmoHot93Hm4GHgH8DvBl4UAjxY2u5ME1A0NnVdjeGZZHx87ixYayYCllpsXhpSN/nuw9+te/z81MnAIjU5rueI9wKVRHt/bzCwtRioRmAfussfgO4QUo5BSCEGAfuAT6zVgvTKMI24DFv/QcN1WtVUqKCjI8QSSixcMrrv66XM89++/Mc+PpbORL/Ehe+4tXLnl+amQAg7nTPjhNulTp2z8eRhompYxaaAeg3ZmGEQhEwO8B9NS8BI2jWl9gAYpEP+kIZyVHsuBKLMFtLszKq85MAlGZPL3OmwllQYpF0u4uF6VWp92NZoMVC0z/9WhZfFkJ8Bfh48PePo1p0aNYYMxCLJOs/O6Iwd5YxwEqNE02osSSeFouXhFdRF32n3zqavBKXrOyeHWd4VepGb7HwjYh2Q2kGot8A97uBDwGvCH4+JKX81bVc2EbmwU+9nye/8elz8lxhG/CUrOB767sTDJsIRjOjxFKhWKy/xfNyRlZUzMftUyyssgpsZyjh1Gudz/GqOKL7/G0AaWjLYiNRr238bgh9u5KklJ+VUr4r+Pn7tVzURufC5/6c1H2/1/f5hx6/lwc/8fsreq6wDbghJMXC+lZx1/LKDRXPbiGeVGIRZmttJsrFHJ57bnbdsqYsBFnpr44mXm1mQeVmOreAsfwartnbssCwsHTq7IZg+vQx5Pt28dwDX17vpfSkp1gIIQpCiHyHn4IQ4rxMg/Fcl2GZ40LvRU4fO9jXfebu+zDXPP/HK3o+22/uOEq5mRU9xmrhFFRfqPTIVuJBgFvW1t89tppI3yf3R6/kxPuu44XH/nnNn8+oqa9RvxX6WWeGulTe48J8Z7GI+FVcow/LQge4NwTTJ75LVDgUTj6z3kvpSU+xkFKmpZSZDj9pKWWm1303K/MzpzGFBODE/f0lg5lOkahwqFYGv7DafoW6VK3Jy/nu6ZLnAr+sxCIzsgXDNCnLKGKTWRbFwgLbmWavd4IL/+FNPPDBf0eltHZxGcsJ5pn3UXQpfZ8Rf44T1l4ASvOday0iso6/rGURwdJuqA1BLafeR7+0vpvB5dAZTQOSm5po/J461l9+vOWoC2oxNzvw88X8CjPGKADVwvqO8hDlOcoySiyueg6VRRyxyUarzp9VdQwPX/EeHhn7V7zq7Md54m9/bc2eLxKIhVlf3lDP5+ZIiBpz6UsBqOWmOp5n+1U8s3vHWVCWhRaLjUE9r2KBoryxR/VosRiQ4qzqyfNc5ACXVp8mN7/8bsD2lEVRyg3+YYhTJWeNAVAvru+HyazOkxdNg7IqYpjO5nJDFabV+5vccRk3/eJHOWbsJpo/vmbPF3XVRiIUjV7MnzkGgL/1AABuMIhqMTZ1fKu3GwozQkR4umvwBsAvqvfRqmqx2FTUFlTqYvkVbyUiPA7d99ll7xMNxKJSWIFlIauUY1uB/jNm1opIfYGi2RSLmhFvpPZuFirzSizSY7vU32Z6TavnY37/FfqF6ZNqbXuuAbq7LWKyhrR6WxYYKu7hums7WvWhv/8Ax55/ZE2f4+WOCNy7dn1jjCHohhaLAfHyKqh4+et+nBmGEAeXLzcJLwj1wmAxh3qtii08nMQ29dx9ZsysFXFngYqVbfztGHEi3uYSCzenNgNDW/cAULfSxNZQLBK+sixi3vIWWmVWuUCHtl/AAimMytKdqPR9otSRy1kWgVh4aygW9VqVVz7xW5z9+l+s2XNsBqygdUu8R6HlRkCLxYCI4hQFGSeZHuLo8L/g0sKD1Kq9L5iJYFZ1vTSYmVkpBuKQ2Q70n165ViS8PHV7qPF33YwT8TbZPIvCWWoyQmZIxYmcSKZxQV8LkjKo0O/jObycsnpGt+2mIDJEqkstVcepYwkfEenecRZAmJHG+WvF2RMHMYVsXAw1nYnW1HUh6W2MMQTd0GIxIJHKNAvGMAD2lT9ESlQ4+MCXup4vfZ+kVLtGb0A3Utj+24hlKco4ora+H6a0zONGm2Lhmgmi/uYSC6t8llljuNGx1YtmScm1EQunXiMhVGFdKBq9MAqTLJAilkhRtIaI1pdehBsZd5HlYxYA3hqKxdxJlVpud1inpkkisCiy/sauRtBiMSDx+iyFiNp1Xvbqf0lZRqk8849dz6/VKthCZZ34lcHEohaIhRlLURKJRk7+euC5LhlZwo+PNo9Zm08sYrUZ8mbzNcpolpQsr0n1fDFIeJgnTUpUcJe5cNuVKeYNlexQjQx37A9VDxo7Crs/y8J1104sKmdeACDubuyL4HqT9tT7mBTVFaXXnyu0WAxI2pmlYquLSSyR4ph9Men8oa7nl1prIwacdlerBLMs4inKRorIOs60yM9PYwiJSIw0jvmRJDE2fpuCQUg7s5SjY80D8SEMISn0qHE5c/LwioK45SAVetbcAiz6rHQgVZ+mYI8D4MRGSHXYiYYuUSPSO8AdisVaxizE3FEAUhvcvbKeSN9nSObJo9LR83Od06E3AlosBmTYn8dJbGn8XbWHG2ZkJyotLToGtQzqQd8gK5ahaqawF6VXPnPf3X2l7q4G+TlVOGSlmrtuP5IgITeXWAz7czjx8cbfRkK53Uo9amQmPv2ryE//1MDPVQkSHgoxFZNaTiyG3BmqMbU2Lz7KkMwvsXjqQa8uM9rbsmgEuJ21E4t4UdWsZKRuNtmNUjGHLVxOWyqhojDXfajVeqPFYgDKxZya55BsioUTHSbdw9dYLTXFIlIfbIflBpaFHU9Rs9JEW9qU5+amufxrb+X5L/75QI+5UioLascTzTQvpNgposLp2tDu5Ua1XCRDCT+1tXEsklSWVLlHq5VYbYaM39vFOH36GA9+qn0ScVhkWUvuVM+R7y5IrlNnRC7gp5SwiMQolvApLLSvy6kGY3ijvS0Lo2FZrN17N1JT2VsJUaOq5550JOzvlU/tB6CyoMViUzA/pWYOmJltjWN+fISsLHT1aVeLzd1iP4VXrYSzIuxEBjeSJt6SMTN98gVMIZHnqOqzmlcXpVi2KRbCDiq517Adxrlk7qy6uFlB9hmAnVTJDNUeNTJRt0hqmQD1ka/fxU3P/S4zZ040jtVLweYhq2o6asXugjM3dQpTSER2h1pjWr0PudnJtvOcwA1lRpM91yOstXVDOfUa2/yzzKHqcnIbeMe8nhTn1Pvnj14MQC3fudByI6DFYgAKwZSy2FDzYtLY4XWpznaCC8Is2TbLoB/8oElfLJnGszONrCqAwtkXATBq5+ZCXZ05BkBmbEfjmBFVc7irpc3hk84HRW/2cPM1xjJBCm2pu4so7peW7f0ly+r+uenmkKOwyDI6pno91Xs8x8JZVUUeHVZWiJ0J4hyL+kO5wWcmspxYmGqS3lplQ509cQhL+JxIXAlAcX7jXgTXk0rQsiW24woA3OLG7Q+lxWIAKvPqi54cbV5MzJQKhubnOncAdYO4w6y1lfjAYhEUbCWz+NEMaVlqtGeozaqLh+GcG/M+OvFtTostbNmxv3HMiIVisTksi/KcqmNIje5sHEtklGXhFLtfyBOBiBd7tHMxg1qD8lxTLMLsuNTWC4DeFfrhONXU+G71nMPKVVbNtV+E/bqyLCKx3mJhmCpm4Xtr06Z87uR3AahuuQ7Y2O6V9aQetP0f3atE1S8N3uXhXKHFYgDqQauP7JbdjWN24MPv1gHUryqxKMa2DZyvLwOxSCTTiHgWU0hKYaHegtoFW+dALDzX5cLS40wM3dCoPwCwYqpNeb28OVIjnQ7vb2pIvb/d0p6l75MKxKJXzMEK4lVhh1EAGXw2RrYrAe5Vh1OfD6q3tyorJDWiXKFOvj17xqspsbCXFYvQDbU2lkXlrMoQTF30KgBqhY27Y15P/MCSGNm6mxxJjLIWi5clD376jzl19NnG337hLJ4UDI813VDxrHIHLN7hNe4TXBDqyZ2kWiyDvqiXqUuLiB3FiKusnLBzrV1Su+BIH20iXipHnvo2GUoYF31P23ErngqWuTksC79wBlcajIw3LcdkKosnBbKLWNSq5UYdTbVHzMEO0p7dfFMsRC1PUcbJjqjPUCgeHdeWO40jzcbahkaVWPiL3BZ+XdW92PFlxCKIWfhrFLOQs0coyRjbLlJ9rNxzLBbVcpEH/+ynyM1ucIumNENVRkgkM+RFdkNXu2ux6EJ+YZabnv0vTHzxjxrHzNIU8yKLaTVHl6cCd0C9SwdQqgU1rCY5TkR4VAa4sBpOiXIwHtMKUjjDdMtUVbm97HPQm2n26a8AsP/6N7Ydt+MqeOls8DncE4f7GypjlqaYE0MYptk4ZpgmBZHE6FI9X1xo7gRrPVxVjf5SxaYlYNTylEQCK2Kr2SA9KvSt0hlmxXBjbbFEirKMQnmxWKjPQzQQ8m4YljlGByMAACAASURBVIpZ+GtkWcSLxzlj7SAzrITQP8ftt488cS83zXyWIw93766wmhw/+AQPfvK/DTxh0azOkRMZhGFQMrMbutpdi0UXZk8dBmBk4enGMbs6Q84caTsvM6rEYvEOL8So5ymKBKJhGfT/pTHcMlVUCmSYwhmmW464QWDMX3vLIn362xw19jG6dVfb8WgwLc/dwGLx3Ue+zq6/vYVDj9+77Lmx6vSS9xegKFJd502UWppD1ntYFkkvqMavND8nllOgYiSD50j2rMOJVacarepDFozskrbW0lGWRTTeu85irS2LkeoEufgu7GiMgow3OqueK8LNm9shaWBh5syqj82d/KcPctPz7+Op//6vKBf7T/iwa3MUTHVtqNpDJNyNmyyixaIL+SDbaK9ztJHlknRmKUVG285LprLUpYXs8mUwnSJlkcAKLvaDjEY13RLVYDxmLK0CrbXiPNVKiTHUhSnur61lUS0Xubj6LFPjr1pyWzSYw+1XVx43eewPf4j7P/zLK77/cuRPKjdi7uRzy56bdGYo2WNLjld6VM+3DqTyerRzSQfxqmit+Tmx3QIVU1kAZSPVmJrXiYwzQym6pe1Y0RxashMVTgVfCqJ91ln4/uoHuF2nzlb/LLXMPgAKRqane+X+//UfePDPf3pV11APUr0Xx5oqpQLWB67hsX/8q1V9PqOWpy5NXlH6Dqf+x/e2pUj3Iu7MU44osajbwxu62n3NxEIIcZcQYkoI8UzLsU8KIZ4Ifo4JIZ5oue09QojDQoiDQojbW46/ITh2WAixdiPLFlGdUW+2LTyOPfsAABl3rlFB21ifYbAgMpgd2kUDWG6JqpHETgW7hwGm3VluhbqhvvShWLileaZPqTYK82T6akD3Ujj0yNeJCof4pd+75LZ4UrUr91/CHO69pafInrl/xfdfDm9eJQK4udPLnAlD3hz1+PiS41UrTbTLhbzV9eR36Qrs1GukhNrxJ5zm+VG3SN0KMsrMVM+ZFiPeTFvnAIBKZKjt8QBwq1Sx2xIROmGuoWUxNXEUW3hYYxcBUDSzPWc1jJ79DpdNf2lVBzHJIKtocaxpfvq06sM1t7oDrSynwGlzB0+/5oPsdE5Q+avb+7Jekl6Ouq2+235smKzMb9iBVGtpWfwN8IbWA1LKH5dSXiOlvAb4LPA5ACHEFcBPAFcG9/kLIYQphDCBPwfeCFwB3BGcu+b48yfxpQBg4dAD+J7HiFzASyy9mBSNDJEuX4aIW6RmJoimlGXRy6+9GMur4ARikcyo+3vlBRZOK7E4be8nIWqrblK3UvzuPTjS5KIbbltyWzyp3FByhXO4pe+TkUVGncnlT14hZkElAlDo/RyuU2dY5vGSW5fc5kTSxP3OF3KnJYNJdun91VplnfGa73/cL+FY6v+wZqUaU/OW3D83R1pU8NM72o7X7ZElO1HhVqiJZeZvA2ZExSykt/oxi9kTyopLbr8EgKqVJd7DvZJ258lS4vSxg6u3iGDztti1Vw4SUcQqN+W03QJVM80133cHT13079gtT/c1Rjnr53FjgeszMUpMOAPFNc8layYWUsp7gY7baCGEAN4MfDw49CbgE1LKmpTyReAwcGPwc1hKeVRKWQc+EZy75kSKp5g0tjDFCNbkY+TmpogID5FeejEpR4aIO53FIuaVcKwU8eBi38mH2g3br+BYyvecyir3l19ZoDKtXGTFrKr6LBZ6t5p4KYxN3c9h+zKS6aElt9nRmAre11dmWZSKOSLCY1zOLTsTZKXEy0ok7HLvrJi5qVMYQmKkty25zbWzJLvMm3BLy/f+Cl2Pk4wzLHONav+ELOHZSiwcK028S/zp6GNfByC17/q2415smCGZa9uJCrdKDbvj47QSWhZyAMuiXMxx/4d+idxc7wK78hmVNju+93IA6vZQz1kNQ1Lddub5b/e9luUwg1iOuShpoBqkN4tVHgccdYvUTBV/MoJmm+GIgW7UqmXVPiihvtthzVZutnPN1nqzXjGL1wBnpZRhu9adwMmW2yeCY92OL0EI8Q4hxCNCiEemp196tWiyOslCZCunklewrfAsC9Mqzz2SXXoxqUWGOraLBhWAdq0Uqaz6IAwy0yLqV3BNJRZ2NBZkzBTwFk7iSQHjlwFQ6RFYfSnk5qa50DnMwrZXdz2nLGIYKxSLwrwK0htCMnWye+fel0LWUSKRqPX+TOSmgurtlur8EN9WBZGdCK2JedIY9c47wlAspmN7iQiP/Px0oz7Dj6q4j2en2yr0W6l89+vUZISLr293Bcrk+JKdqOlVqBt9WBaWOkcOELM48ujXufn0R3j+4+/peZ6cO0pF2oxtU83x3NgwmS6WWbmYIy6UdeOcfKzvtSxHGMtZHGsK59ivdn1S3C/hRpTwG0GNS20ZC2FhRm1kjKTyVkSCFi7F+Y3ZeXa9xOIOmlbFqiCl/JCU8nop5fXj40tdRYMy4pylHN9Odcs17JKTzL34JADx4R1LznVjI6Rl511EQlbw7DSprNptDDLTIiYr+C0Tz4pBCqeVn2BGjGAFrq1e+f0vhaMPfxFDSIYOfH/Xc6rEMVY4h7u00LyAzwfZZ6uJ9H3GPHWhzri9EwtKs8pdlRzbteQ2GR/q2s5DVvN4UrBgjHYNUNeC3Ww5cyEAuelTzfqMQCz8aKZrHc74zIMcjl5BLNGeDmsFO9GFmeZO1PBqOH24oYwg/Vt6/VsWYTuSV059rmc6cqxwnDPmjkbcRMZHSIkK9drSDsUL0033YHru6SW3r5SYo0R88UhcJxQLd3Uti4Qs4QZWYlisupxYFAILIhK0bgn7roVNOzca51wshBAW8CPAJ1sOnwJ2t/y9KzjW7fia4tRrjMk5vPQu0kEFqjyo8rXT40svJn58hIwsdRxek5RlfDtFxI4qy2CAmRZxWcW3mmJRNpJYTp5EZZL5yFYicRVgXiuxqJ5SmUQXXP2a7ucYMcwVfvEqLT7dytTRFT1GL3JzUyREjbKMMubP9Qwc1oJWLpkO72+jILJDO3ijlqMoElSsdNcAdXiBEuPKh1+cO0MxP9f22MSGiAhviSDNT09yoXeU/I6l1l14kSm2tJpRca5lpuQBViNm0b9YeGX12RVIzv7f3+h63nD1JPPx5tfWSCo3S75DgVxxXq19knH21g6t2pCp0O0VW+Q+DDdrkVUWi5Qs4wdiEQk7G1R6u6HCvlDxIfU+JoOq/PoGbSa4HpbF9wHflVJOtBy7G/gJIURUCLEfuBh4CHgYuFgIsV8IYaOC4Hev9QJnJo9hCokxvJu9B27Bl4JL8ipjZ3hLh4tJcgxDSPKLmqVVKyVs4UJUfXiKPYq7FiN9nzhVpN2sxK2aaSJOgSHnDMXYduwgG6m+Ro38jNIZ1QAx1j1nv27EsdyVTcurt9SmyLkXV/QYvZg5dQSAY9FLsIXL/Ez3ILdfUBetkQ7vrxl0ni11aOdh1guURJK6lSLWpZreDWavp3aq3IzqwiSloN7GTKj30AiEf3FQ9OjDXwZguIN1FwsuMq19lyy/hmssH7OwrMHFwg82Oo9sezOvLH6Tg4/805Jz6rUq270z1NN7ms+VUjvmQocdczkQixOjt5ASFSaOrI51kQks/SWxpiDwHV3FlPPwey6i6j20G/VHvQWpFohFYkjFQTOBWGzUZoJrmTr7ceB+4FIhxIQQIkyk/gkWuaCklM8CnwKeA74M/LyU0pNSusAvAF8Bngc+FZy7psxPqgtXfGwv6ewIJ8xdZChRllGSqeyS8820cgcsHlwSDrMxYsrVUDLSPXPpW6lVy5hCgt10PdTMJHE3z7g/g5PaSTRIx3XWqDdTtDLFgjna85y6mSCywipyt6gujHkS2MWTy5w9OMUplR6ZG70WgPmz3Z/DKJ1lngx2dOmu3E4osah0EAtVWJfCtVJtLeRbkRX1Odh6wQEAnPzZRgp1JKjMD0WjnG/PCXGPfIOCjHNRB+suFVxkWneiEb+Ga/ausYBmNhQDiEXocrvy3/4+MwzhffU/L7HWnvnGJ7CFS/yS1zWORYPOveUOvngn6JUVvVwlTk5994G+19MNp14jg/pMLo41hQHv1SxmDQttRdDRwA6q55crVnWDwsFs0LolnR3BlUbXmq31Zi2zoe6QUm6XUkaklLuklB8Ojt8ppfzLDuf/npTyQinlpVLKL7Uc/6KU8pLgtt9bq/W2Up5SYpHdrrqBTmWuAmDeGOqYvx5NB+2iF+2cwil5ZuguMlNE+xyNGlaBGi2tpp1Ihh3uBLbwMIZ3Ew/Ewu/RU+ilkKxNU+xQpNaKYyawVziHO2wBcdK+mHRl+TqIQQk788b23wRAcbp7oZRdmWbBWFq9DRBNd097tt0iVTO5pIV8K6K6QEHGGRnfqS4GxSnqQRZVNKWEqCFIi+pwds49xJHkNQ23USuZoEeZV2wRC1nD6yPAbYXZUH7/bp+wPUk6O8KRK36BK+pP8+Q3PtX+uE/8LVOMcODWH2kcC/un1Tq0xAl30RfecDtlGcWdeOlB7lwwmvQsoyrW1DJ4yQrEIiFXb3Z8+J6F3/N+i1VlaQZXGmSGleVlmCY5kcboUrO13ugK7g64c2oHOr5TBSTlDtVmuWB13mUngs6ki5sJhlPyrOBDtHjaXS/Ctt+ixQ3l2WkSQk02i43taYiFt0ZiMeTNUott6XmOZyWIrlAsRGWBsoxSTO9ni7f6tRZy4SQ1GWHrJTcAUJvvHu5K1mco2F3e3yBtOYw9tBL3itStdBCgLneMi5i1BYoihWGaqrdYeboRLA6LLcOizdaWIWdOHGKXnKS665aO60pnhqlLs1GABhD1a/jW8pZFQ3wGqLMw6nlKKJfkdf/6l5gQ20h95/2N13zmxCEOVB7h6K4fbuuflh5RFpDToZmgKE1TllHS2RGO2xeSnX/pbqhi0AF6xlaJk611LrarviurKxbB9zywEpvFqr2/60ZlVolDSy+ygpEhUtNi8bJBFCaYJ9MoOhu9VAUXy10uJqngy+Au2jnVAusgErgY3EiaRBdXxWJqFSUWVqzphvKjTRdYZtuFJNPqb7kGvZnCMZ5eammqcCuelSC2wi+eWVsgL9LIob1kKZFfWN78fvIbn+aBv/jZJcfLxRxPfeMzbccipUmmjTHGtqu23l6PKu6sO0st2jmLLhG4UbzyUssiTJlc0kK+dR31PCVT7Tbz5hB2dbYRLI4HYhEPrJd6y3OceFQZ2FuvXloQCap7wJwYxmqpIYlSwzf7tywYIHXWcoqNXlYRO8rkNf+Bi7wjPPG1/wPAi/d8CIA93/dzbffLhF11S0svglZlhgVDfY5zwwfYWz/SMVFkEEqBu6uUUu97uSUOFA/EIiqcjtlZKyGccGgHVmKzWLW3qytSm6dgtLu1y9YQ0R7V7uuJFosOxEunmTGbO+q9l19PScaopzqWeJANxMIrte+cwt1jNIhzeNEsyT5nWtSCOESYhgcgYs0P1tjOC1u6lXa3LB74i3fwwN/9Tl/P2Uo4xtPILK07aEVGksTlyr50kfoCJTODPabmOUyfWL6CN/rtP+ZVU5/izIn2uoynPvPfeMU//zQnDz3ZOJasniEX2YIdjTFHBqPYudgprM53k52tqPSQcsV1SntOUMK30xjBe1PKL70gxtw81aBSuxQZIeHMNYLFYWV+olGh3xQb48V/ZpYs+y6/oeO6AOYjW0m0uPCisobsw7IQhoEjzYFiFrZbaLwOgOt+8B0cN3Yx9OAf49Rr7D/xOZ6JX8eOfZe23S8WT6oOuZWlmwG7Pk8xaKRn7bqOhKi1vYcrIWwi6A8Fc61bYk0Jr7mxKq9SMasTiGAsdClGY9SluWyxaqw+T8lqF4tqZOM2E9Ri0YFM/QzFWHNHHbGjnPmxf+DSH3tvx/PDdtFiURvmcEpeLKm+DDKaVSl2QXrgU9/8LDPv3cvD/+MneOa+u9vadjiBnzWSaBGLIM0yT5J0ULdRFvGu0/Kk73P51D+SPv61vl97yMJZ5d8Px3h2Q9pJ4tRWlPIYdXJUrAzp7aqHUH6yd2HemZOHucx9HoATD3+h7bbsqW8CMPlMs7vscFArAzBvjhGrdK7iblTnp5ZW50NLQeSitGff80jJCjKa7RqgBoh7eeoRZVnUoqOk3XlkJYcnRSNholmhr55D+j778o9wLP3Knn2eSvHtjNTPNO4Tow6R3h1nQ1xMxACWRcwrNXpZAZiWxcwr38l+/zhP/MXb2MYMzive0vG+eZHBrC61zBLOPJWIusiOX3ozANMHX1qQO2wiGN2qPle1FosmJYvkCWbHr5JYuA0rsdnloNJHsWrSW6AW9IUKcaLDpH0tFi8LpO8z7k1TS7YX31141asYHu++y86JTKPFQEgYeA5HcxK4KsL2HJVnvkBGFrhs/pscuOctnHrfKxqumDCTwo43xcIKLkjTLVZPRSQwu7QumJ+ZJEuJjDN4dkVpRsVtOhWptSLsJIaQVCuDV8QmvAL1SIYte1Qlem26d/rssW+pJLqSjGEe+2bjeH5hlovrSkQ4+SCg3GiqVkaJXdEeI1nvnJKYmwkGSXWo3g7plPZcLCxgCAmxDHaQXlsrLL0gJv0ijh3El+LjDMsFjFrQuj4Qglg8qXajgSCdeOEJxljA23dr9/8QwEnvYlzO4jp16vUqhpDIyPJ1FgAe5kBuqLhfxLXaCwOvfcPbedHYxw0LX2KeDAde/+Md71s0Mx1nNaS9BWpRJZS7L7qKkowhT720IHcYw8nuVJ+rcCSu69RJi0rj+7Nas+NDKzF0VwJUiCOWSSnP+DmcaHtShR8fISsLG7KZoBaLReQXZkmKKmR3L39yC8UOg0tCsUgGYmEGlkHY/iGbe54j9mVEfvUwD1z0Tvb4pzj+1H0AeEEmhd1iWUSCC1Ih2rR6qmYSq0sDurMvqirbEX/wgFl9Qbk2hrfs6XmeiAYttouDB9lTfh7HHiI7Mk6eBGKhdyfQoRe/yFFjH88NvZYLCo80rJkjD/4jlvCZJcv4wlMAzEweV260ISV2tfhWhr3OYlEMxKJTdX5IuUOb8vB9NOJD2IH1WCu171ZVs8QCfjTYdSbHiAkHuzxJSTSTF4RhUGoRpDNPqX5QO67uXj0PYAztwRI+M5PHqZbVpkH0a1kIE+H374ZKtvSyajy/aTJ/k2oxf3DrD3atyalY2UZVdYj0fYZlDi8+0nisY9GLGVp4idnxlTnKMspQUDMTttgpBBux8Puz+L1aKeGEw1SLZVEzYj2rxD3XJSuL+In2bEORGCUiPAr5jTcESYvFImYmlCvEHu19kVxMpVMzwZqakhd+gcxgpkU5P4/nuuypHyE3pNo4XPj6O9Vtk2rQvRdkUsQTmcbDhWmWtUTzolY3EthdPpSFCbXbTooqxQE/fH5+Uo2Q3dLbDWUEYlEbsNYj7Djrx9Rrmja3EetRa3F24giXOc9xdvcbEBe+nmEKHHn6OwA4B79GQcY5tOvH2OudIL8wy/ykqgiPjQXB7eQ2Rsl1DGpW51UmVmq0u2VRMdPYi2pkmlkwWWJBgNpZ1CiyUi5gC6/hQjSDRpQj1ZNUjPZdekkkMQOXonXyO0wxws4LejdZjo/vA2Du9BHq1VAslo9ZALhYfVsW0vdJykqjl1Ur137/T/LwNb/H5W/uHhur2cNLmgkW8vOqmC3ZTCwoJXYztExrluUwq3PkRWZJrKkYpLaH35/Vmh0fjsdtzQCrG3HMHm1wcnNnMYREJNqTZsJmgoW5jddMUIvFIgpnjwGQ2rJ/oPt16qwZ5qWHtM60mDjyDAlRw9ypZhSPbdujTPAZJVYyEItYqvnlDDvXyqGm1VO3kkS7VA57M80YwPzZ/oaxhJhFNcaz9QvQ8bwgAB+m+vZL2HFWBPUFudhOhurd02dfvFe5oHbecgf7bvxBAGae/DLS99kzdz+HUteTvOS1GEJy/Ml/pjStrJTsNvU+mll1gZjrUJjn5tUXc2hLd2uyZqWJee2vsRq4NyLJEZJBDMlbNNMirOo3go1CdEjtard7k1TN9jnZFSNJxFHzDPYUHudE+tpl51Jkt6v07vLUi9SCOJcZ7c+y8AaIWZRLeSzhtyVZhAjD4IZ//QtkRzvHfAC86BAZ2f7/lw8q6s10063q22lSXepV+kUFzTNLWuyEWVHh98ctr44bSlXxt/+f1404Ea+7GyrsC2Vl2jPw7ODv4tzGmx2uxWIRYSHXyI4LBrqfGxsh47fvVNSUvOYuLxY0/qsX55h+QfnWxy5WmS7CMJi0dpIoKL99mHYXb3FDbdt7GY+mv4ft1ze7tLuRFLEuA5BiuWa/pfz0YC21YtVpcl3qSlqJBNWqg1aRhx1nzaCdcz21i63e2a6B8uyLX+BFYx97LrmGsW27OWrsI3PqW5w4+LgKrO77HvZd/Rp8KSgeuR8nqJUZ26nex+iIckksnO3g6ipOUZUR0pnhpbcFOHZmSYV2vRhmuw2RyoSNItsvQKUgx98KXIjJEWW92MKlbrW7dGpWCtstMnH0WcaZx9vTvdtvyNbdKojrzB3HCYZQGXZ/loUnLITsTyzCbgSdxKIf/MQoGdr7pxXnlFhEM02xkLEsSVF9SemzMSfXmD5XEKmGa69aUGIRGdkHgLdM76Z+aR2PG7JcsWphRnU7ig21p6aHBYzV/MZrJqjFYhFhIdfoMu6XJfeLj5Be1FnTckttroYwAOaU5nEnHqcqI+y+5NrG7QuJfYzV1EVO1EtUpN22s7ejMV75n/4vey+7rnHMj6RIdBGLkeoJThjqdVR6FKR1IlWfpmgv373XToTNDAeLi4QdZ62U+j8RI/uJCYfZDjv/qVMvcrnzHGd2N2dpTW25hYtrz3L6wU8DsOfGH1KFXeZeklOPYuQnyJFszOFIBYH68uzEksc3K9PMi87V+SGenSW1KO3ZDXzh8fQQ0VgiCFC3X4DC+Ql2Wr3O7FjzcxW2tA6pW2niXpHJJ+8BYNsrvq/rekJiiRSzZDFzJ6kHTQjNaHKZewWvCROjX8sieB1hksWghDMewupqaPa0Sow0L5iikYK8cp990stRD8SiNdYUFlWmA2vTr61OfVLELTbG44Z4VrxnsWpxQsVltu1/Rdvx1LCyzmq5jddMUIvFIiLFU0wZ48ua/4sxksrX2NpZM5ySF5Js8aGm55/jRGR/WxsHZ+gCtvlTVCslhFOiIpbPavHtNAlZWZI94Tp1tnuTTA6rgTnuwmDtNIb9Oerx3tXbAKO71ACm6oBdY8OOs9GM+j+JbVEWwOzJF5ace/TejwGw49V3NI4lL/8+bOFy5bGPctzYzfa9Krd/avhq9lWfJ1Y61VYrM7xNxS7qHUQzVp0hb3Vu9REiY1lSstJm+YSB00RmFGEYKmOqvnh+grIs4g2xaF4Y/UXB4rBo0zj+bWbJsufi9gtJN2atrcTLp3Fr6uJk2X26oUT/bqhqkOUV9rIaFDPYFLS6V5xg95xuiRU1GyquvIo5I/N4QSxMxZrUe+IFKbSh12C1illbx+OGeFaCaI/6IzH9PAukGN3W7vocCjIu/YK2LDY8qeoZcvbyF8nFRMJmgvPNwFTUK+O0fIjSmWF8KZCVBXbXDzGfvbz9MbZegiEkky8+h+GWqYo+3AnRFLbwqNXadzGTxw+qwOqu66nKCBT694HWqmWGyeMvU70NMLplpyq4mh+sa2x4EU0EQ6GGdgRT/84eaTvPdersfOFvOWxeyN5Lr2kcv/iG26jJCBlKTI4322EYu28kQ5mLyk9SsJs+9KHRbao1Rn5p4DDpzHWtzg8R8SEMISm0XMTClMlUo+YlibVILMK0zWTQEiZiR5lHicTiYLEfzZKSJXblH+d46uq+NyzF2DaG6mdwAzdUJN6nZTGAGyrMHLLT3V11vYgGvvhSy47ZK6oL4tBYUyzCjL9KYWXN9MImgn5cvZ/1SJpY0GInDHRnR7aqWMYKxwEvpnU8bogfSRLv0dkgWzjMaXv/kvc4kcpSkjEoabHY8Ay7U5Tj3VMouxH6XVubCaq89OYX1zBNiiJOfOYZ1RVz29Vtj5HdpcRj4eRzWG6ZWh9i0ehou8hsnz2uzNzMzsuZM0baWkIsRxgEtrLL/z8Iw+CMuZ1YYbAAethxNhUMfNm6R4mFM9MuOo9//oPslqcp3PSutuOxRIoXYqqLa+LyZjuMbQdeC6gMsNZaGcM0mRUjREpLg+hZf556rHfDxMZMi5Y+Q6KapyojjWy3ipFc0lU4bJaYHm669HKGeqzF/n8ZzZAQNRWD2bV8vCKkntzJuD+NF4pFtL+YhS8sjD5TZ8NZ4/HUysQinl3aP02UZynIeFu6bVivUh1gVn0roZsrTChwIplG1baoLlCUcSJ2lJJIdJ1sOCidUoplRBWrdqqXkL7PzvqLFDIXd3y8eWMYq6zdUBuaeq3KmJzHy/QuROtEYjjorJlrXkwSsoIXWZQeSZKLyqqdwchF7W0ctgctrKtnDiqxMPoXi8qiatRqkIK77YKryFmjxKv9f/jCEaPLVW83zo/vYrg2WEykcREdUReRWDyp5p3nmgHoWrXM7qc+wCHrYq75vn+75DEql7yJaYa55MbbG8d2XXAl8wRdP9PtYpezxogtGq/qOnWGZR6/S6uPkE47XqOep9hSK1GzUksy02RlHkeaJJJNK6IUuLxCl0uIaPl7y1Wv77meNob2EBMO9dljQLNF9nJ4WBiyv8p7rxS63Hq767oR+uJbZzVYlVlyi3ojhY0V6ysc6BU2EQynCHp2phFrMquqoSNAVcRXPLSrFZVSXMK3F6UU2wks4S+x+AHOnjpKWlRgy+VLbgMoWCPEa/2nD+fmpvvqq/ZS0WLRQn72LJPGFqzRwdJmodlZ021pF52U5SWuhrKZJiUqONJk92WvbLstlRlWF8y5I0T8Ko7Zx8SzoId+dVGBkTF3mHnSDI1toxIdI+X2/2EKg8Cp8f4KE2vpvWzzzgzU8iPsBZGZxgAAIABJREFUONu6qzwdv4SrFr7Ok//0CQCe+IcPsI1pKv/iPR1dMjf+6DsZf++xtnGjwjA4Hle1CZGR9lqZcmycjNMuFgvTkxhCYqS7p30C2OEI25Y+Q2a9QKUlZbLeIb3WqOXIi1Tb+qtB1W5YpNl4vEAsFkix97Lre66nldi4+rwaMyreY8f6c0P5wsTo0w21uMB0UMJmgl5L641YfZai2f54YUNFt0PTxn4ImwiGbi8ZGyItKniui+XkKQWB6KqZXJU53I3xuLF2y0IEc2gqHYpVzx5+HID0ns4xqUp0lJTbf8xm4i9/BPEnV/LAx/7rS27C2AstFi2M7djLzt9+gRve9O8Hvm/YTNAPWg2oD1FzSl5INfiwnrD2EOvgW562d5EuHcf2yrjm8oHKSNAOuVZq/1Cmisc4G1EXeye+hRGvf7EIg8DDW/srTBQj+4kKh+nJY30/R9hxtpU9b7+Lk9Zervjnf89Dn/0TLnj+gzwXOcBVt/5w348LUNmmRDi5ZV/b8Xp8K6OL/h8arT6yvRsmxoNMtnpL0V3ELbRlwagAdftuNVJboLSo+M4JXF5h3U1I2OL6xcTVbW2rlyOzTQVsM6Vj6nH7tCx8w+pbLKjmcKTZlso9CPFEmqqMIFoG+yScBSqLeiMlwx5Z5ZVZFmETwdDtJVomEMacHNWg+2/dSGD3GNr1wmPf7KuhYWM87iKXohF0i652SCmvTKg27DsvvnbJbQBObJyhAbou7KwfRQCveuGPOPn7N/Dc/V9a9j4rQYvFKhGxo6plRfBlCLM5QjdRSJhbP5vubIIW0/vZ5p4kKit41vJiEU2G0/La8/u31E+ST+4DwE9tIy0qVPosnJP5M9SlyVCPIqtWEttUrv9MH11jQ1TH2fYLz8iWnWz7pa/xQvQANz79XsaZh9f/5sCZaXtvfSuPpW5l75Wvar8hvX1JNXtpVmWJJYZ7B/ND94vbIhZRt0itRSz8aIbkojRm28lRNha5KAKXV3SR/7/RX2rXzT3XspixXer/f7sTDHuK95cN5QsLs0+xMOqFtl5WgyIMgwUx1BYzyvgLS3ojpQLLRa5wRkvYRDAcG2AGRZ/F3Bxxr0AtaOjYq5gVIPH5f0fuM7+07POFjSPNRS7FMH25Vl76nTNnvssUI12LGP3UFrKUqFWXn0BZyM0xRJFnLnoHj938Z8T9EvY9v7EmvaW0WKwieZHBqqmLSRhDWCwWbuDb9Lde1fEx5MiFDFFkzJ/DiyzvTogFvvDWatT8wqxqQjeiLiJWsGue67OK2yqfYVaM9H1hGNl1CQDlM727xraiOs4uzdlPZ0e48J1f4uHs7Tw09ANccfMb+37MkB37L+O6X/48iUUjcK0hFYOZnWzGRaoL6uKVXqZhYqpDm/K4X8RpqZWQ0cySgrKY27xAhZhDKpYSZkiF7DlwM4+lXsuFr+vcubUbmaFR8iTIUsKTAtvur5GgL/qPWZj1PGXRnwh1YyJzNfsKj+J7Hr7nkZUFvEW9kUzLoiDjiD5n1S+m0UQwEIvQWivnZ0j6BVw7nC3TvZjVdeps9ae4qPrsshfsahBbsZKLrMTALbXY4gcYLh7mTKy7q9tMq43L/NTyccCpE4HrcWw/193+FrLvfpz4T/7dikW9F1osVpFSSzPB5pS89guFFwwwGrqgs086vl3VC0SF09dcgnB4Tuu0vDNHlZkb26YeKxY0yAsD18s+ZnWKnNU7O6iVLbsuwpUG7mz/tRZhx9lOxOJJbnjnp7jxP3684+0rJTYaTE5rGa/qBfnsw1t6Z34lU1k1ErVFLBLB4KMQ0SEzLeEXcBa9zqtuu5PHb/6f7Lzgyrbj6ewI1/3y3Yzv2DfAq1LMGEGCBXbfFwopTMw+xSISzBp/SVz0/YyS48hT36awMKPavSSXFn6WRBKzx4yWngRNBMM4VjSob6kV5kjLYmOAmB9JdU1tnZk8TkR4xITDkSfu7XhOSK1Rxd9uJUaCbtFOpd2y8FyXXe4JytlLuj5mNLBy8zPLi0V+8jBAo81/PJlm5wWdvRYvFS0Wq0gxtp0d1SPUa9XGlLzQtdAgvZ2KtNl9xY0dH2N0z4HG79Je/suZDMTCbykwygcNBEf2qEBvGKiuzPWXsZR2Zil3mRrXiYgd5awxjp3vP3027Dh7LhnZqb6gpclm4Z8onqUkY0uskMUIw6AgkhgtFzGVwNC8X5he2yoWKVnEjba/zlgixbW3v23lL6QD+ZiyHqti+Sl5IdKwMOjPDWUvcrmthAtvfhO+FMw8/nkWgr5QVnrp56xipLD6nFW/mLCJYEjY4LE6f5qYcJDx4Ptip5a4DENmJ5oWcu75b/R8PifYFMYWxZ/CbtFutd3VdfrY88SEg7Gte4PIxIja1JRnly+krU2rDdr4rs5puKuJFotVJPLKtzDGAk999SONGEJ00UXomh/5ZWbe8k+NNhSL2bb3EtU2AhB9tG2IxZO40oCWi5gz9QKuNNi+X30gh4MGec5Cf3Ouh/1ZnMRghYlz9k7SlaWtNDrR7Dh7bsVi2+6LKMo4nG22wI5Uppk3+svwKYkUZuAeqdeqxEUd2ZLA0HR5BDNJnDoZyshz8DobnVTpXyx8I9J3zGLx4KOVMDy+nUORSxk9/U1KQfFqNLs0VlQxVY+slRA2EQxpzE8P6neMIIYh7LQqZu3gZioH3QhyJEmf6T2IqTn4qD32EiYZuIuqxKePPAHA0N72GqtWsuNBW/0+vq9i4ThFGSc7Mngh8aBosVhFDtz6w5wwdpJ+8sONIqZYcumucvdFneMVAFbEZtJUu0TRh2Wh5iDEMVqqUaMLRzhjbMWOKt91dmQLdWkhC80P3wP/+108/v43LgmElYs5VQHbR/V22/1Se9ji9tdSpNlxdmU5+yvFME0m7P2kc03LIlabobBMq4+QBXsrw2V1ISkG7UpaC+vsMDOt2D4/Ieysu5bIIZW5VjMGsCyEhdWnGyq+yOW2UuZ2vo6LnEMUTqi5I4nhpUHe1qrrQYktioWFEwjD+p2woaMIYgqdelC5c8fxpeC7o9/PhdXnesYtmoOP2j9DseCzEM6lCamdVjNmdl1yDd0YHlfC7/fRdSFanGDK3LomMYrFaLFYRQzTZPLSt3KpexCOKvM13sWC6MVcTH3xjT4bwlVItInFUPk4s7Fm2qswDGbFMFZZ+eel77Nv4m6uLX+H5x/8Svtzn+m/ersVObyPIYrk5pcvJlrccfZckstcwi7naEMkU+48lWVafYQUdvwLLvReZObMycasbbOlV1Lo8gjTa4u5sOPs2r9Oe1T1vnIGdkP1JxZJWVxSpbwSxq/7lxhC8v/aO/PwuM763n9+s2k27ZsteZHlfYvteImDsweyNTcJEEqg0Dy0KZBAIFBoaUsvkIYnbW/aQm8JhUJuwm2aEBKWXMKTNk1oQoF4iZ14S+J9kxdJ1mJppNnf+8d7jjTSzGg0ysxIlt/P8/ix58yrc97jo5nfu/x+32/lvh8DUJnBQyTuCqYp/G792cMcuX9FzjqCQKJ3hFWpvdcUGNCzXo9VrOewgkWmOgjXueN0SjWexe/BJ1EOvfGr7Bcc7CWpZITxEQwnnqhR1qqes2/RJo1jLntqSZgKHKHcwaIqcpJeb/6KExPBBIsCs/zGT9CnfKzp0cqhEyliilRYHgze8X04Bx3+Ibe8WDTCrMQJBisXjGhzzlWLL6y/pE8eeZsZ6Hz02Ct/P7Jdhw4W3pr8qtg99fp67UffzNl2tOJsSWlcTgUDnDmhNaiqkl3EfOPbzK9bpVVvj2x5LqOwnp1sYKvRDlj36Z6gREY+BBt1rUUsn5mFw4VrHHsWyUSCAGHUBOXJU2ldcSmdVA15qacKK9roquuRX7LJ41tpSR7nkGV4lY1UEUEY3muqi+lZr7fCLoi01ZIz+IIPtHHWPYPWte8hqYSevS9lv2DkHCG8aXUx/oD+7I4OFrUDB2n3zR/zHgB6HNV4wmMPvFQySUPiDJFgfq6eE8UEiwITrKhmT+MtuCRJVLkyFt7lwlGvN2Ld4yyuijgDuK1gcWL/63gkjqt55JpoqKyeoOXF3bZDzya2lV/LqsEtHN6zeajdQJcegVXU5xcsqqzN43Mn01VjRzOkOFte+mBROVdP/88ceI1IeIBKQjmlPmzmr3wX3ZSjDr40FCw8KYEgYBXu2QZIkT49+ygrH39m2USpbdZfQHHH+NJmAXC4cI1jZmF7jYs3c/ZaPjicTg5Vad2rXgK4PenBLemt1MkDKYoA7kH9xdm1J/sX92gRQZuQBGlAP4uAVaznsRwoMzk81kRPEfI1UVnbyBHnXIKnN6e1sdHGR+mfcZfbQ0S5IWXGHwkP0Jw4Sbg6eyaUTb+7Bl9k7ELaro6T+CUC1XNznq8QmGBRBGZd9xmSStLcs8bLzIuupp0a6ltW5G4MRJ2BoWrUzv3bAKhfMDI1N+arp9qqCnUc/RWdVLHgzocZUGV0/sdDQ+3iZ3VGU9WM/H4BG+boD0C042COlimKs1Xjz7gqFE2LdXX3wPGddHfo0aYzh9SHjcPp5FD5eub1biZmyVaUjQgWVkGZFSyilliir6L4waKmvolB5SE+DokYG+Usw6siOYs1B7JUKU8U12It/GgLKo5GvJU4RRHqH6618EUtqfeT2TecR4sI2gykFH/aNgH2/lJsVKV4PBalXp0lVq5H6+2161kQ3pPRjhcyGx8NXVe8OGLD+x0nD+7CLQncM5dnbJ9KpKyOisTYVdydlpy/tz4/o7aJYoJFEZi1YAVvBN5Fl3NiI+fZC1fR8NXDzJgzvnS4mCtAWVL/UiZO7WRQeZi1cOTMIhlspJIQ4YF+5p57jaPla6iqm8HOxttY3fMiJ4+8zauP38+ag9/muDRRUZnfOnuwolqb8PQcydl2tOJsKamoquWkNODpfHPIPdBTNbbURyqJ1qupo4fo4d8Cw0tPwLCNZ2Skf4Jd0FdMxOHgqHs+Uf/476Vyza14JM4bz/ztmO0GrRnSRI2PRrPg0luIK0eaLpSNLbAY6h0eWZdbWkmtAztJxDMvnY0WEbSxU34TSobcEIeVD0bOLNrbDuOSJE7LTc+z4Eq9b5Gl3sIT70+zx7UJMzJYdB/bC0D1nNyDwLi/gepk95iV2H2WnH9l04KsbQqJCRZFYtHd/0bVx39ekmsl3AF8VrAo797LcXdLmne27UG9b8u/U0838TmXAdBy8xcB8D96DRv3/x17A+vxf/KFCWVXdLiaCIRyF/6NVpwtNWd8C6gN7Wegy5L6qBn/BuHc9dr/u7X9BWBYy8gm1QApeU6fv6K6NPc5+7PPs/qufxp3+6WXXM8b3vUsPfT9MRMTBu39mQJt1FdU1bK9+gZ6Z2aWYR9OQR4eWdcku+lEiwIe3pN5djFaRNDGLv7sk8DQ3oLP2mBOjCqa627TRW7+Br1v2Lr2Pfr4m5mXv8oS/Wn2uDYRhxdnfDhYRK1U2OrxzNqDDfgkSv8oNelUYp1HAGiYXfwaCzDBomgEyquobcxf6nwiJD3lBNQAKplkdvRgmqkSgNeSmIjs0IquTWu0rPeMOQvZUXMjHhVjy8qvsvoLz0243/3+WdRGc6fPZlKcLSXhmiXMSrQRsT5sFfXjt9BtnDWfI47ZQ2vgo7NgBh0BXNE+Th/bz0VtT7HTuy7junwxCFj2rnn9zI1fo5IQe5/5etY2UavwrCxYuHqRDfc9waV/8L8yvmcHJXvzOdTXg18iHKy7FoDO3Zm/uPsObwWgbu7IgjdbYqc/RbjSbz03NapSPGTVWFQ369F6Vd0MDjlaqGp7OeM1vcnQCMmXVKIOH64UsULVf4a4clBVmzst3VWh2/SMobrg6D1GFxVZa7YKjQkW0wDlKScgYU4eeZsKQpBBd8qu4l7W8wrt1DArRWpizd2PoL6wjw3v/9w7yteOVbbQoM7m1NPJpDhbSjxNF+GSJO7jvwaG89rHy+k6PSLuU760GVzYEcAd76P93z6JoKi74+HCdLpILFi1ideCV7Hq+ON0ns78xRQPDXuNlwI7KEWtYNFjLRc6Zl1MmzRS1pZ5ZhE89hJHHLPTlm+TVgV96t6F7S+iIiNTdBNdR0gqob55OGOpvfU2lsb2cnBX+nUDaiDNs8Ym6vTjTgxLijhD7XRJ1bgUhb3VejmxrzP74MsfOkGnK796qHeCCRbTALvA6OROPeKqal2b1qaqQc8WAhLmWMXaEUHB7SkryOjEVdeKQxRnjo2dEZVJcbaU1M3X0tALQq/RSyDv0bhvqV6ayJQFE3GVszi8k4vC29i17PM0tSx+5x0uMg233o+HGAee+VrG9+3srtFVysXCZ6W3xqx6lT4rWJRVzaStci3zBt5I804J9fWwKLyb0/WXpZ/QyuIKpywXOZxO+pUPiYxchnKdO06H1AwVtAIsvenTDKgyzr74zRFth4yPyjJnicWcfjzJ4WBRFunkXJZ9mtEE6/Rsd7A7e7Cojp6ir0Q1FmCCxbTAVrZVR39NQglzlq5Pa1NVO4OYJSOiWi4vSj/KZ+oRXdfxt8ZsV5biKzAZNLcuI6zcVDBAjyP/L8CF668jqlwZhfVibu2Jvte9gvW3f7EQ3S06sxeuYnvNjVzc/hN6u9IdFUd7jRebgBUsklaQGrTW+gO1zUjLJqro5+hb20b8zP5Xf4FH4gRX3pR2PlviI+YeuUE/ID4cowyQAoMnOesemSRQWVPPrrobWdX9At0dwyoIQ8ZHWYJFwumjLCVYBKJnCXnGl+xQZaWux3rTPeNBCxI2JNuJlo/Pc6YQFC1YiMgjItIuIrtHHb9XRN4SkT0i8rcpx/9MRA6IyNsicn3K8RusYwdE5EvF6u/5jNNStm3q2c4J5yx8gfRRu/ag1h+a5jXXp71fCGYtWUdIeYntfGbMdv5EHxFPYTJrJoLL7eG4S28y9rvyL5jzByvZE9hAjzd9ryPmqyes3JT/7sN5GRhNNpWb7sIjcfb96kfpb4Z7iSj3hGqGJoIt0WHLwUd79BdmZX0Tzav1rK5918h9i8hbzxNSXhatv47R2Bvm8VHWp4MOf5pbXk30NCF/+mh9xrs/Q5nEePu5/z10rN+Scxltj2uTdPvxpijbVia6iOTwerepqK4nqpyoLJIfHaeO4JEEjprS1FhAcWcWjwI3pB4QkauBW4FVSqnlwEPW8WXAHcBy62ceFhGniDiBbwE3AsuAD1ltDSnYMuiz1Ck6AtkLfs65ajhFPU3zlhSlH8GKanY33MyqnhfpPJ1ZgTY8GKI62VVyxdnRdJfr/6dw2cTSWpfe+zTLPvN0+vEPPsCZD/8nsxdmF4qbiixcc6W29N33XNp7tvFRqfCUeRlUHsSa0ai+MySUUF3XRFPLYk5Tj/vEcCW3SiaZe/Y37AtcPGL5aOh8liVu0jtyYBBx+HGlZCvFohHqVSeJ8vSK6LlL17Kr7GJajzxBLBoBIGRliY02PrJJugN4lW6biMepVr0kxinQ6XA66ZYqnAPpMz2ALksZ199QmhoLKGKwUEq9AoyuKrkb+Gul9P+gUqrdOn4r8KRSKqKUOgwcADZYfw4opQ4ppaLAk1ZbQwplKfnv8frsBT/hTX/KmcsfKGpfmq6/DxdJ9j/3zYzv7/jXv6CCEP7Vtxe1H7lINugxR8w3sbRWry/zXkdlbSNzF2cXiZuqOJxODtddxZL+LWlFeq5oHwMZ9meKSWoKsmOgnW6pHEomOF65hpb+14f2LY69vYMZdBCd9+6M5yqz9lpklOd51OnHk+KW137iEE5ROLOM1hMbPkEDXex84f8CELbqT2xr4zTcAfyEUckkPWdP45JkTq/3VM65aigLZw4WIavGoqq5NGmzUPo9i0XA5SKyWUReFhF7cb0ZSE3FOGEdy3Y8DRH5uIhsE5FtHR2Z/4OnK6ky6IGWi7O2u+jq21l97R1F7cvsBSvZ5d/AouM/SsuKOrR7M+tO/ICtldez8orJjfnBOXrkrzKY71yoBFbdhk+ivPXrn4047oqN9BovBQOOIK6YDlru8Fl6UzaGnUtuooZzbPmXewE49dr/A2Duxsy/U+WWWKGrYuQXdcwVHGGt2n1Sj9Z9jZlH6xdd9QFOyAzKd3wHlUwOpxRnqT9RngAOUYQHQ/R22F7v489eCrlrCcQyV3HHz+qsrYZZuXWmCkWpg4ULqAE2Al8EnhIRKcSJlVLfVUqtU0qtq6+/sL4AUo1XmpdkNlUqJY5L76aWXnY+/8jQsUQ8Tvynn6ZPAiz86D9OYu80c1Zs4qQ0UD7/ksnuypRh8SU30EuA+J5nRxzXXuOlnVkMOoK4rWARiHYScg9/Ia+5/k42172fjacfZ/MP/4bg8V9yxDGHGbMzVzLPnLuYXdc8ysrrRhpOxV0BvMnhAc1gu/a8qGnKPFp3OJ2cWnkPi+L72P78Y0RDlmdNeZZKdEs1eqC/l/5OrblmGxuNh6i3jsoskh+uc8fokJqS1iqVOlicAH6sNFuAJFAHtAGpC4WzrGPZjhtS8FvT7HZqqGkY/y9jsVhx2a0cccymetcjqGSSZCLB1if/ikXxfRxa95dUZVAaLTUVVbU0fWU/Ky67ZbK7MmVwe8rYV3kZi3r/e2hdHsCb7CeWpUq5WERdwSFPi4p4N5GUvSVxOFj3ye/yuv9S1u19kCXhnZxuGDvDb+UV7037Yk26g/gZDhaJrqMklFDfnN0f++JbPsVhRwsztj5I3LLk9WUNFno2FhnoHzIyKs+jADQRaND7HBnkTQIDbWlZW8Wm1MHip8DVACKyCPAAncCzwB0iUiYi84CFwBZgK7BQROaJiAe9Cf5sxjNfwATK9TLUKV/p1i/HQhwOziz9GAsSBzn6wCrC989k44Fv8IZvA2tvumuyu2cYA9fyW6gkxNubnx86pr3GS7sMFXOX40v0o5JJalQ3cf/I1QKny8Wie37IIdd8XJIkuPLGvK+RLCvHr8JD+kvOvuN0SN2YFfdOl4v+K79CszpD81t65hyoyLwM5fTawaKX+Dmd1VSVR7BwlDfiEr3fkUp722FaovvpD7aM+1yFoJips08AvwUWi8gJEflD4BGg1UqnfRK405pl7AGeAvYCzwOfUkollFJx4NPAvwNvAk9ZbQ0puNwejjmaGZxz5WR3ZYiLbvo4O71r6fU0snPGe9m8/H8y/+6nSuLoZZg4SzbdyqDyEHrjp0PHtNd4aeti4p4K/CrEud4uPBJHgukbw/5gJbWfeJatax5k2cb0+oqceIK4U6xVgwNtdHlyz3pXXvk+dnrXMkudJqmEQBYjI9fQzKJvyOs9n+JXe3/D3u8AnfnV9vg9CIrm//Hn4z5XIXDlbjIxlFIfyvLWR7K0/zqQJlCjlPoF8IsCdm1aMvvLuymNBcr48AXKuehLY5jGGKYkvkA524OXMK/zv0gmEiSTCQISRpWVti4mWaYNkE6dOUYl6ZvTNjUNzdTces+ErmEXs4b6evCU+aiPtXG4cuO4fjZ484Mkf3Q9/eKjIks9jduvl+5ig6Ehr/d8dn781breI3R2OFhsf/4x1g78hlcX3sfG1txS54XEDPOmCeJwmFG7oTCseD8NdLH16YeGPKoLYXyUF2UVeCRBz0mtAmtrJRWSIWvVvh72/ubn1NGDLLhmXD/buuIStta/jzZ3S9Y2Hp8+fzzchzfSMW6vdxt7fyPcrfc7es+eoWXLVzjgnM+6D/5FXucqBEWbWRgMhvOTNdffyc43Hmfl3r/j4MxFrCR7lXKxcFg1EYOntHRMeW3hEzfsYtZwqJfIlkfpJcCKd2dc+MjIhnu+h1Iq6/sea2aRCPdRHu+i05+f70S1pee24PUH2f3mU7gTYearPrpveQKX25PXuQqBGYoaDIYRiMPBjI/+C3Fx0fjS54FhyYxS4bTMiaRLzyxsIcxC4rasVftOH2DluVd4s/6mvCRNxOEYU9LFZ50/Ee6nKtmddwGoP1jJllUPcKByE57EADPjx9k69y4WrNqU13kKhZlZGAyGNBqa57Ht4r9k3XYtx+YpoJfFeHBbwSnYd4iochbFQMp2y3NvfwSPxGm48o8Ken5vUAeLZKiTCgZQgfFXb9tseO+9wL1Dry8tVOcmgJlZGAyGjKy9+RPsCGjJb2+wNIqzNra3eWP0ON1SVZT9OK+VxbQi8jr7XItoXVHYAk2ftQzl6j0KgDPLJv35ggkWBoMhI+Jw0PoHj/Dqoi8yb3lpK91t74w6ejiX58bwuK8RGJ4t9SzJlrw5cZwuF4PKQzCkRTXz8XqfiphlKIPBkJXK2kY2fvjLJb9uoGLY2zzkrh2j5cTxV1gOeqqMZdd9rCjXGBQv9TGd+hoowiZ9KTEzC4PBMOUIpBgtRb3FCRY+fzkDqozd1dcSrMjf12Q8hMVHHVpw0DY0Ol8xMwuDwTDl8PoCRJUTjyTG7QGRL+Jw0Hbb0yxtXVGU8wNExAcKkkqoqj+/l6HMzMJgMEw5xOGg3/LQyMcDIl8WrrmC8iLaxUYd2oypWyompTaikJhgYTAYpiQh0dpK+XhATDWiTh8AvY7iLHOVEhMsDAbDlCRseWgUQ+qjVMSdWha931OcfZdSYoKFwWCYkoQtd77yuvM3iyjh0jOLSNn5b8hmgoXBYJiSxNy6qK26CFIfpSLh1rOjeJE26UuJCRYGg2FKEndXMKg8Wf0izgeUSy9DSfn5HyxM6qzBYJiSVF/5SXYdXM+G81h6X3n0UprrPN6ktzHBwmAwTEkWrr4cVo/trT3VEY+eWfiqmia5J++c8zdkGwwGwxRHLGvV4Hm8SW9jZhYGg8FQJOZt+gC/7T3JJQtWTnZX3jEmWBgMBkORaGieR8MffWOyu1EQzDKUwWAwGHJigoXBYDAYcmKChcFgMBhyYoKFwWAwGHJigoXBYDAYcmKChcFgMBhyYoKFwWAwGHJigoXBYDAYciJKqcnuQ8ERkQ7g6Ds4RR3QWaDunC9ciPdUr8KJAAAGHklEQVQMF+Z9X4j3DBfmfed7z3OVUhnNN6ZlsHiniMg2pdS6ye5HKbkQ7xkuzPu+EO8ZLsz7LuQ9m2Uog8FgMOTEBAuDwWAw5MQEi8x8d7I7MAlciPcMF+Z9X4j3DBfmfRfsns2ehcFgMBhyYmYWBoPBYMiJCRYGg8FgyIkJFimIyA0i8raIHBCRL012f4qFiMwWkV+KyF4R2SMin7WO14jICyKy3/q7erL7WmhExCkiO0Tk59breSKy2XrmPxQRz2T3sdCISJWIPC0ib4nImyJy6XR/1iLyOet3e7eIPCEi3un4rEXkERFpF5HdKccyPlvR/KN1/ztF5OJ8rmWChYWIOIFvATcCy4APiciyye1V0YgDf6yUWgZsBD5l3euXgBeVUguBF63X043PAm+mvP4b4B+UUguAbuAPJ6VXxeWbwPNKqSXAKvT9T9tnLSLNwGeAdUqpFYATuIPp+awfBW4YdSzbs70RWGj9+Tjw7XwuZILFMBuAA0qpQ0qpKPAkcOsk96koKKVOKaW2W//uQ395NKPv9zGr2WPAbZPTw+IgIrOA3wG+Z70W4BrgaavJdLznSuAK4PsASqmoUqqHaf6s0ZbRPhFxAX7gFNPwWSulXgG6Rh3O9mxvBX6gNK8CVSIyc7zXMsFimGbgeMrrE9axaY2ItABrgM1Ao1LqlPXWaaBxkrpVLL4B/AmQtF7XAj1Kqbj1ejo+83lAB/B/rOW374lIgGn8rJVSbcBDwDF0kOgFXmP6P2ubbM/2HX3HmWBxASMiQeAZ4D6l1LnU95TOqZ42edUicjPQrpR6bbL7UmJcwMXAt5VSa4AQo5acpuGzrkaPoucBTUCA9KWaC4JCPlsTLIZpA2anvJ5lHZuWiIgbHSgeV0r92Dp8xp6WWn+3T1b/isAm4BYROYJeYrwGvZZfZS1VwPR85ieAE0qpzdbrp9HBYzo/63cDh5VSHUqpGPBj9POf7s/aJtuzfUffcSZYDLMVWGhlTHjQG2LPTnKfioK1Vv994E2l1N+nvPUscKf17zuBn5W6b8VCKfVnSqlZSqkW9LN9SSn1e8AvgdutZtPqngGUUqeB4yKy2Dp0LbCXafys0ctPG0XEb/2u2/c8rZ91Ctme7bPA71tZURuB3pTlqpyYCu4UROQm9Lq2E3hEKfX1Se5SURCRy4BfAbsYXr//c/S+xVPAHLTE++8qpUZvnp33iMhVwBeUUjeLSCt6plED7AA+opSKTGb/Co2IrEZv6nuAQ8DH0APFafusReRrwAfRmX87gLvQ6/PT6lmLyBPAVWgp8jPAV4CfkuHZWoHzn9BLcgPAx5RS28Z9LRMsDAaDwZALswxlMBgMhpyYYGEwGAyGnJhgYTAYDIacmGBhMBgMhpyYYGEwGAyGnJhgYTBMEUTkKlsN12CYaphgYTAYDIacmGBhMOSJiHxERLaIyOsi8h3LI6NfRP7B8lB4UUTqrbarReRVyz/gJyneAgtE5D9F5A0R2S4i863TB1O8Jx63CqkQkb8W7T+yU0QemqRbN1zAmGBhMOSBiCxFVwZvUkqtBhLA76HF6rYppZYDL6MraQF+APypUuoidMW8ffxx4FtKqVXAu9DqqKAVgO9De6q0AptEpBZ4L7DcOs8Dxb1LgyEdEywMhvy4FlgLbBWR163XrWjZlB9abf4VuMzykqhSSr1sHX8MuEJEyoFmpdRPAJRSYaXUgNVmi1LqhFIqCbwOtKAltsPA90XkfWipBoOhpJhgYTDkhwCPKaVWW38WK6W+mqHdRHV0UrWKEoDL8mDYgFaMvRl4foLnNhgmjAkWBkN+vAjcLiINMOR3PBf9WbIVTT8M/LdSqhfoFpHLreMfBV623AlPiMht1jnKRMSf7YKW70ilUuoXwOfQ1qgGQ0lx5W5iMBhslFJ7ReTLwH+IiAOIAZ9CmwptsN5rR+9rgJaI/mcrGNiKr6ADx3dE5H7rHB8Y47LlwM9ExIue2Xy+wLdlMOTEqM4aDAVARPqVUsHJ7ofBUCzMMpTBYDAYcmJmFgaDwWDIiZlZGAwGgyEnJlgYDAaDIScmWBgMBoMhJyZYGAwGgyEnJlgYDAaDISf/H3vb4ibIlozgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztOe_9DqO6wA"
      },
      "source": [
        "x[\"age\"].plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9A4_RYhk0AS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR3ozxwNf8gG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4L12ajPEYK"
      },
      "source": [
        "x[\"bmi\"].plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeSr3sp4PJaY"
      },
      "source": [
        "x[\"children\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgwFOsndPreJ"
      },
      "source": [
        ""
      ],
      "execution_count": 174,
      "outputs": []
    }
  ]
}